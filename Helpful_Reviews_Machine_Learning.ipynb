{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpful Reviews Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOTEFILTER = 10\n",
    "MIDDLEPERCENTAGE = 20\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Open DataFrames\n",
    "df = pd.read_csv('df.csv' nro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>asin</th>\n",
       "      <th>helpful</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>Helpful_Votes</th>\n",
       "      <th>Total_Votes</th>\n",
       "      <th>Helpful_Percentage</th>\n",
       "      <th>Review_Length</th>\n",
       "      <th>Sentence_Length</th>\n",
       "      <th>Word_Length</th>\n",
       "      <th>Helpful_Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>[0, 2]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This is one my must have b...</td>\n",
       "      <td>12 11, 2003</td>\n",
       "      <td>A2S166WSCFIFP5</td>\n",
       "      <td>adead_poet@hotmail.com \"ad...</td>\n",
       "      <td>close to god</td>\n",
       "      <td>1071100800</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>268</td>\n",
       "      <td>9.800000</td>\n",
       "      <td>4.306122</td>\n",
       "      <td>0.021653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>[7, 9]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A timeless classic.  It is...</td>\n",
       "      <td>10 7, 2002</td>\n",
       "      <td>A2XQ5LZHTD4AFT</td>\n",
       "      <td>Alaturka</td>\n",
       "      <td>A Modern Rumi</td>\n",
       "      <td>1033948800</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>813</td>\n",
       "      <td>13.818182</td>\n",
       "      <td>4.260000</td>\n",
       "      <td>0.657681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I discovered The Prophet f...</td>\n",
       "      <td>01 23, 2013</td>\n",
       "      <td>A19N3FCQCLJYUA</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>A book everyone &amp;#34;shoul...</td>\n",
       "      <td>1358899200</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>870</td>\n",
       "      <td>18.111111</td>\n",
       "      <td>4.148148</td>\n",
       "      <td>0.650476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Can't say enough about Kah...</td>\n",
       "      <td>06 27, 2012</td>\n",
       "      <td>A3FFNE1DR5SI1W</td>\n",
       "      <td>A. Morelli</td>\n",
       "      <td>phenomenal piece of litera...</td>\n",
       "      <td>1340755200</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>427</td>\n",
       "      <td>11.833333</td>\n",
       "      <td>4.845070</td>\n",
       "      <td>0.650476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>[3, 5]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Anything I've read by Gibr...</td>\n",
       "      <td>11 16, 2005</td>\n",
       "      <td>A2X4HE21JTAL98</td>\n",
       "      <td>Antiquarian</td>\n",
       "      <td>Flawless</td>\n",
       "      <td>1132099200</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>485</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>4.775000</td>\n",
       "      <td>0.468122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        asin helpful  overall                     reviewText  \\\n",
       "0           1  000100039X  [0, 2]      5.0  This is one my must have b...   \n",
       "1           4  000100039X  [7, 9]      5.0  A timeless classic.  It is...   \n",
       "2          14  000100039X  [1, 1]      5.0  I discovered The Prophet f...   \n",
       "3          15  000100039X  [1, 1]      5.0  Can't say enough about Kah...   \n",
       "4          17  000100039X  [3, 5]      5.0  Anything I've read by Gibr...   \n",
       "\n",
       "    reviewTime      reviewerID                   reviewerName  \\\n",
       "0  12 11, 2003  A2S166WSCFIFP5  adead_poet@hotmail.com \"ad...   \n",
       "1   10 7, 2002  A2XQ5LZHTD4AFT                       Alaturka   \n",
       "2  01 23, 2013  A19N3FCQCLJYUA                Amazon Customer   \n",
       "3  06 27, 2012  A3FFNE1DR5SI1W                     A. Morelli   \n",
       "4  11 16, 2005  A2X4HE21JTAL98                    Antiquarian   \n",
       "\n",
       "                         summary  unixReviewTime  Helpful_Votes  Total_Votes  \\\n",
       "0                   close to god      1071100800              0            2   \n",
       "1                  A Modern Rumi      1033948800              7            9   \n",
       "2  A book everyone &#34;shoul...      1358899200              1            1   \n",
       "3  phenomenal piece of litera...      1340755200              1            1   \n",
       "4                       Flawless      1132099200              3            5   \n",
       "\n",
       "   Helpful_Percentage  Review_Length  Sentence_Length  Word_Length  \\\n",
       "0            0.000000            268         9.800000     4.306122   \n",
       "1            0.777778            813        13.818182     4.260000   \n",
       "2            1.000000            870        18.111111     4.148148   \n",
       "3            1.000000            427        11.833333     4.845070   \n",
       "4            0.600000            485        16.000000     4.775000   \n",
       "\n",
       "   Helpful_Rating  \n",
       "0        0.021653  \n",
       "1        0.657681  \n",
       "2        0.650476  \n",
       "3        0.650476  \n",
       "4        0.468122  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Total_Votes']>=VOTEFILTER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_value = df.Helpful_Percentage.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Helpful_Rating_2'] = (df.Helpful_Votes-df.Helpful_Votes*expected_value) - (df.Total_Votes-df.Helpful_Votes)*expected_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['reviewText', 'overall', 'helpful', 'Review_Length', 'Sentence_Length', 'Word_Length', 'Helpful_Rating', 'Helpful_Rating_2' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>helpful</th>\n",
       "      <th>Review_Length</th>\n",
       "      <th>Sentence_Length</th>\n",
       "      <th>Word_Length</th>\n",
       "      <th>Helpful_Rating</th>\n",
       "      <th>Helpful_Rating_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>This is one of the first (literary) books I re...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[81, 92]</td>\n",
       "      <td>1542</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>4.258865</td>\n",
       "      <td>0.902674</td>\n",
       "      <td>12.902213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>The Prophet is Kahlil Gibran's best known work...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[8, 10]</td>\n",
       "      <td>2294</td>\n",
       "      <td>22.705882</td>\n",
       "      <td>4.883289</td>\n",
       "      <td>0.683638</td>\n",
       "      <td>0.598067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Gibran Khalil Gibran was born in 1883 in what ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[8, 10]</td>\n",
       "      <td>712</td>\n",
       "      <td>19.428571</td>\n",
       "      <td>4.103704</td>\n",
       "      <td>0.683638</td>\n",
       "      <td>0.598067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Certainly the words are of Kahlil Gibran, but ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[10, 12]</td>\n",
       "      <td>700</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>4.675000</td>\n",
       "      <td>0.728884</td>\n",
       "      <td>1.117680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>I evidently misread the writeup, I thought it ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[0, 13]</td>\n",
       "      <td>178</td>\n",
       "      <td>11.666667</td>\n",
       "      <td>3.885714</td>\n",
       "      <td>0.021653</td>\n",
       "      <td>-9.622513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>The Prophet dispenses ultimate wisdom to his l...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[8, 10]</td>\n",
       "      <td>528</td>\n",
       "      <td>14.714286</td>\n",
       "      <td>4.089109</td>\n",
       "      <td>0.683638</td>\n",
       "      <td>0.598067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Maybe I just wasn't in the right mood for a he...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[3, 15]</td>\n",
       "      <td>885</td>\n",
       "      <td>13.076923</td>\n",
       "      <td>4.059880</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>-8.102900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Gibran gets right down to the bedrock of what ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[97, 103]</td>\n",
       "      <td>931</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>4.257310</td>\n",
       "      <td>0.944421</td>\n",
       "      <td>20.760086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Kahlil Gibran (1883-1931), the Lebanese-Americ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[17, 20]</td>\n",
       "      <td>735</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>4.991525</td>\n",
       "      <td>0.812844</td>\n",
       "      <td>2.196133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>A prophet has waited twelve years in a coastal...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[207, 215]</td>\n",
       "      <td>2048</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>4.354054</td>\n",
       "      <td>0.962563</td>\n",
       "      <td>47.858433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>I first became aware of Kahlil Gibran when I r...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[156, 167]</td>\n",
       "      <td>883</td>\n",
       "      <td>16.200000</td>\n",
       "      <td>4.260870</td>\n",
       "      <td>0.943198</td>\n",
       "      <td>32.387713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>I appreciate getting the book at the great pri...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0, 56]</td>\n",
       "      <td>219</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.307692</td>\n",
       "      <td>0.021653</td>\n",
       "      <td>-41.450827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>I picked up this book after being inspired by ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[10, 28]</td>\n",
       "      <td>234</td>\n",
       "      <td>14.666667</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>0.443169</td>\n",
       "      <td>-10.725413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>This book was given to me as a gift before I j...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[19, 25]</td>\n",
       "      <td>805</td>\n",
       "      <td>23.333333</td>\n",
       "      <td>4.598540</td>\n",
       "      <td>0.769690</td>\n",
       "      <td>0.495167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>I originally read this early in college and di...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[4, 15]</td>\n",
       "      <td>388</td>\n",
       "      <td>13.600000</td>\n",
       "      <td>4.727273</td>\n",
       "      <td>0.296945</td>\n",
       "      <td>-7.102900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Being an Atheist, it may seem strange to some ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[11, 14]</td>\n",
       "      <td>1657</td>\n",
       "      <td>21.071429</td>\n",
       "      <td>4.620209</td>\n",
       "      <td>0.712935</td>\n",
       "      <td>0.637293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>I bought this book for my son who had his stol...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[10, 12]</td>\n",
       "      <td>248</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>4.377778</td>\n",
       "      <td>0.728884</td>\n",
       "      <td>1.117680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Gibran's words strike as deep and sudden as li...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[10, 12]</td>\n",
       "      <td>482</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>4.862500</td>\n",
       "      <td>0.728884</td>\n",
       "      <td>1.117680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>An unusual departure of an imaginary prophet ....</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[12, 15]</td>\n",
       "      <td>535</td>\n",
       "      <td>11.375000</td>\n",
       "      <td>4.953488</td>\n",
       "      <td>0.734130</td>\n",
       "      <td>0.897100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>This man was a son of a pastor, but worshipped...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0, 27]</td>\n",
       "      <td>1120</td>\n",
       "      <td>24.142857</td>\n",
       "      <td>5.140244</td>\n",
       "      <td>0.021653</td>\n",
       "      <td>-19.985220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>I am alive like you, and I am standing beside ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[28, 32]</td>\n",
       "      <td>3309</td>\n",
       "      <td>20.655172</td>\n",
       "      <td>4.511945</td>\n",
       "      <td>0.873456</td>\n",
       "      <td>4.313813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>This book was a philosophical touchstone for i...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[53, 130]</td>\n",
       "      <td>1599</td>\n",
       "      <td>24.545455</td>\n",
       "      <td>4.761194</td>\n",
       "      <td>0.610340</td>\n",
       "      <td>-43.225134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>I can never quite make up my mind on this book...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[9, 13]</td>\n",
       "      <td>1834</td>\n",
       "      <td>17.800000</td>\n",
       "      <td>4.217009</td>\n",
       "      <td>0.631645</td>\n",
       "      <td>-0.622513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Gibran's Prophet is the best example of how si...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[14, 18]</td>\n",
       "      <td>1376</td>\n",
       "      <td>13.888889</td>\n",
       "      <td>4.658228</td>\n",
       "      <td>0.746042</td>\n",
       "      <td>0.676520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>\"The Prophet\" is Almustafa, called \"the chosen...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[11, 40]</td>\n",
       "      <td>4291</td>\n",
       "      <td>18.925000</td>\n",
       "      <td>4.456724</td>\n",
       "      <td>0.406507</td>\n",
       "      <td>-18.607733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Khalil Gibran's The Prophet is a truly awe ins...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[14, 17]</td>\n",
       "      <td>1348</td>\n",
       "      <td>18.416667</td>\n",
       "      <td>5.032258</td>\n",
       "      <td>0.773493</td>\n",
       "      <td>1.416713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>At first, I was going to tick Beryl Bainbridge...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[15, 15]</td>\n",
       "      <td>2371</td>\n",
       "      <td>16.833333</td>\n",
       "      <td>4.579208</td>\n",
       "      <td>0.897752</td>\n",
       "      <td>3.897100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>Ms. Beryl Bainbridge writes Historical Fiction...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>2478</td>\n",
       "      <td>19.954545</td>\n",
       "      <td>4.571101</td>\n",
       "      <td>0.832820</td>\n",
       "      <td>2.598067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>How people can make these types of mistakes is...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[9, 11]</td>\n",
       "      <td>998</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>4.567251</td>\n",
       "      <td>0.721450</td>\n",
       "      <td>0.857873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>I didn't realize this was the children's book ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1, 19]</td>\n",
       "      <td>213</td>\n",
       "      <td>7.166667</td>\n",
       "      <td>3.744186</td>\n",
       "      <td>0.082990</td>\n",
       "      <td>-13.063673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Beginning with &amp;quot;The first six words I'll ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[15, 16]</td>\n",
       "      <td>427</td>\n",
       "      <td>11.285714</td>\n",
       "      <td>4.171053</td>\n",
       "      <td>0.866562</td>\n",
       "      <td>3.156907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>This is my surprise book of the year. It was a...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[11, 11]</td>\n",
       "      <td>1359</td>\n",
       "      <td>18.307692</td>\n",
       "      <td>4.670996</td>\n",
       "      <td>0.845897</td>\n",
       "      <td>2.857873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>I ordered this book through one of Amazon Mark...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[0, 11]</td>\n",
       "      <td>292</td>\n",
       "      <td>18.666667</td>\n",
       "      <td>4.053571</td>\n",
       "      <td>0.021653</td>\n",
       "      <td>-8.142127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>Schwarcz is a Professor of Chemistry who has w...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[12, 17]</td>\n",
       "      <td>5240</td>\n",
       "      <td>20.928571</td>\n",
       "      <td>4.867206</td>\n",
       "      <td>0.685279</td>\n",
       "      <td>-0.583287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>I bought this book based on two 5 star custome...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[8, 21]</td>\n",
       "      <td>6550</td>\n",
       "      <td>20.245283</td>\n",
       "      <td>5.044933</td>\n",
       "      <td>0.437458</td>\n",
       "      <td>-7.544060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>I am continually puzzled by the publishing ind...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[36, 49]</td>\n",
       "      <td>760</td>\n",
       "      <td>11.250000</td>\n",
       "      <td>4.451128</td>\n",
       "      <td>0.794493</td>\n",
       "      <td>-0.269474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>In addition to writing an engaging story that ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[10, 11]</td>\n",
       "      <td>740</td>\n",
       "      <td>14.555556</td>\n",
       "      <td>4.589147</td>\n",
       "      <td>0.774136</td>\n",
       "      <td>1.857873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>The concept of this book was interesting to me...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[8, 12]</td>\n",
       "      <td>256</td>\n",
       "      <td>16.333333</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>0.603476</td>\n",
       "      <td>-0.882320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>I was extremely happy with every aspect of thi...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[3, 11]</td>\n",
       "      <td>783</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>4.467153</td>\n",
       "      <td>0.271698</td>\n",
       "      <td>-5.142127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>I was so excited about this book. Something ab...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[9, 12]</td>\n",
       "      <td>888</td>\n",
       "      <td>15.363636</td>\n",
       "      <td>4.197605</td>\n",
       "      <td>0.666079</td>\n",
       "      <td>0.117680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>Sara Gruen has penned a most enjoyable book ab...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[17, 20]</td>\n",
       "      <td>1819</td>\n",
       "      <td>29.363636</td>\n",
       "      <td>4.520249</td>\n",
       "      <td>0.812502</td>\n",
       "      <td>2.196133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>I really wish publishers would rate books like...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[8, 23]</td>\n",
       "      <td>377</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>4.171429</td>\n",
       "      <td>0.412172</td>\n",
       "      <td>-9.024447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>It was mentioned in the public radio and on th...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[15, 22]</td>\n",
       "      <td>1717</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>4.355987</td>\n",
       "      <td>0.700787</td>\n",
       "      <td>-1.284253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>This really is an excellent book with an inter...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[7, 18]</td>\n",
       "      <td>737</td>\n",
       "      <td>12.400000</td>\n",
       "      <td>4.701613</td>\n",
       "      <td>0.424206</td>\n",
       "      <td>-6.323480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>I thought this book would be outstanding by al...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[10, 20]</td>\n",
       "      <td>437</td>\n",
       "      <td>12.285714</td>\n",
       "      <td>3.964706</td>\n",
       "      <td>0.528682</td>\n",
       "      <td>-4.803867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>\"Water for Elephants\" by Sara Gruen is an utte...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[16, 18]</td>\n",
       "      <td>2645</td>\n",
       "      <td>15.933333</td>\n",
       "      <td>4.457627</td>\n",
       "      <td>0.830432</td>\n",
       "      <td>2.676520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>It took me approximately 8 hours over the cour...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[19, 26]</td>\n",
       "      <td>1439</td>\n",
       "      <td>16.800000</td>\n",
       "      <td>4.560000</td>\n",
       "      <td>0.751769</td>\n",
       "      <td>-0.245027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>So much has already been written about the sha...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[8, 10]</td>\n",
       "      <td>749</td>\n",
       "      <td>13.777778</td>\n",
       "      <td>5.008264</td>\n",
       "      <td>0.683476</td>\n",
       "      <td>0.598067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>Jacob Jankowski is pushing 90 and wallowing in...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[35, 43]</td>\n",
       "      <td>4161</td>\n",
       "      <td>27.400000</td>\n",
       "      <td>5.022189</td>\n",
       "      <td>0.841326</td>\n",
       "      <td>3.171687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>Have to say I'm wondering what all the fuss is...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[34, 40]</td>\n",
       "      <td>3363</td>\n",
       "      <td>20.533333</td>\n",
       "      <td>4.468908</td>\n",
       "      <td>0.862231</td>\n",
       "      <td>4.392267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            reviewText  overall     helpful  \\\n",
       "14   This is one of the first (literary) books I re...      5.0    [81, 92]   \n",
       "18   The Prophet is Kahlil Gibran's best known work...      5.0     [8, 10]   \n",
       "19   Gibran Khalil Gibran was born in 1883 in what ...      5.0     [8, 10]   \n",
       "35   Certainly the words are of Kahlil Gibran, but ...      5.0    [10, 12]   \n",
       "36   I evidently misread the writeup, I thought it ...      2.0     [0, 13]   \n",
       "41   The Prophet dispenses ultimate wisdom to his l...      5.0     [8, 10]   \n",
       "48   Maybe I just wasn't in the right mood for a he...      3.0     [3, 15]   \n",
       "49   Gibran gets right down to the bedrock of what ...      5.0   [97, 103]   \n",
       "50   Kahlil Gibran (1883-1931), the Lebanese-Americ...      5.0    [17, 20]   \n",
       "56   A prophet has waited twelve years in a coastal...      5.0  [207, 215]   \n",
       "60   I first became aware of Kahlil Gibran when I r...      4.0  [156, 167]   \n",
       "61   I appreciate getting the book at the great pri...      1.0     [0, 56]   \n",
       "63   I picked up this book after being inspired by ...      2.0    [10, 28]   \n",
       "67   This book was given to me as a gift before I j...      5.0    [19, 25]   \n",
       "69   I originally read this early in college and di...      3.0     [4, 15]   \n",
       "70   Being an Atheist, it may seem strange to some ...      5.0    [11, 14]   \n",
       "71   I bought this book for my son who had his stol...      5.0    [10, 12]   \n",
       "75   Gibran's words strike as deep and sudden as li...      5.0    [10, 12]   \n",
       "76   An unusual departure of an imaginary prophet ....      3.0    [12, 15]   \n",
       "77   This man was a son of a pastor, but worshipped...      1.0     [0, 27]   \n",
       "82   I am alive like you, and I am standing beside ...      5.0    [28, 32]   \n",
       "90   This book was a philosophical touchstone for i...      1.0   [53, 130]   \n",
       "97   I can never quite make up my mind on this book...      4.0     [9, 13]   \n",
       "114  Gibran's Prophet is the best example of how si...      5.0    [14, 18]   \n",
       "116  \"The Prophet\" is Almustafa, called \"the chosen...      1.0    [11, 40]   \n",
       "120  Khalil Gibran's The Prophet is a truly awe ins...      5.0    [14, 17]   \n",
       "130  At first, I was going to tick Beryl Bainbridge...      4.0    [15, 15]   \n",
       "133  Ms. Beryl Bainbridge writes Historical Fiction...      4.0    [10, 10]   \n",
       "137  How people can make these types of mistakes is...      1.0     [9, 11]   \n",
       "145  I didn't realize this was the children's book ...      1.0     [1, 19]   \n",
       "146  Beginning with &quot;The first six words I'll ...      5.0    [15, 16]   \n",
       "162  This is my surprise book of the year. It was a...      5.0    [11, 11]   \n",
       "168  I ordered this book through one of Amazon Mark...      3.0     [0, 11]   \n",
       "175  Schwarcz is a Professor of Chemistry who has w...      2.0    [12, 17]   \n",
       "176  I bought this book based on two 5 star custome...      2.0     [8, 21]   \n",
       "178  I am continually puzzled by the publishing ind...      1.0    [36, 49]   \n",
       "229  In addition to writing an engaging story that ...      5.0    [10, 11]   \n",
       "284  The concept of this book was interesting to me...      1.0     [8, 12]   \n",
       "288  I was extremely happy with every aspect of thi...      4.0     [3, 11]   \n",
       "312  I was so excited about this book. Something ab...      3.0     [9, 12]   \n",
       "343  Sara Gruen has penned a most enjoyable book ab...      5.0    [17, 20]   \n",
       "363  I really wish publishers would rate books like...      1.0     [8, 23]   \n",
       "364  It was mentioned in the public radio and on th...      3.0    [15, 22]   \n",
       "381  This really is an excellent book with an inter...      3.0     [7, 18]   \n",
       "396  I thought this book would be outstanding by al...      1.0    [10, 20]   \n",
       "402  \"Water for Elephants\" by Sara Gruen is an utte...      5.0    [16, 18]   \n",
       "413  It took me approximately 8 hours over the cour...      1.0    [19, 26]   \n",
       "435  So much has already been written about the sha...      2.0     [8, 10]   \n",
       "476  Jacob Jankowski is pushing 90 and wallowing in...      5.0    [35, 43]   \n",
       "494  Have to say I'm wondering what all the fuss is...      3.0    [34, 40]   \n",
       "\n",
       "     Review_Length  Sentence_Length  Word_Length  Helpful_Rating  \\\n",
       "14            1542        15.000000     4.258865        0.902674   \n",
       "18            2294        22.705882     4.883289        0.683638   \n",
       "19             712        19.428571     4.103704        0.683638   \n",
       "35             700        21.000000     4.675000        0.728884   \n",
       "36             178        11.666667     3.885714        0.021653   \n",
       "41             528        14.714286     4.089109        0.683638   \n",
       "48             885        13.076923     4.059880        0.228122   \n",
       "49             931        19.000000     4.257310        0.944421   \n",
       "50             735        24.000000     4.991525        0.812844   \n",
       "56            2048        17.500000     4.354054        0.962563   \n",
       "60             883        16.200000     4.260870        0.943198   \n",
       "61             219        10.000000     4.307692        0.021653   \n",
       "63             234        14.666667     4.250000        0.443169   \n",
       "67             805        23.333333     4.598540        0.769690   \n",
       "69             388        13.600000     4.727273        0.296945   \n",
       "70            1657        21.071429     4.620209        0.712935   \n",
       "71             248        15.000000     4.377778        0.728884   \n",
       "75             482        13.500000     4.862500        0.728884   \n",
       "76             535        11.375000     4.953488        0.734130   \n",
       "77            1120        24.142857     5.140244        0.021653   \n",
       "82            3309        20.655172     4.511945        0.873456   \n",
       "90            1599        24.545455     4.761194        0.610340   \n",
       "97            1834        17.800000     4.217009        0.631645   \n",
       "114           1376        13.888889     4.658228        0.746042   \n",
       "116           4291        18.925000     4.456724        0.406507   \n",
       "120           1348        18.416667     5.032258        0.773493   \n",
       "130           2371        16.833333     4.579208        0.897752   \n",
       "133           2478        19.954545     4.571101        0.832820   \n",
       "137            998        11.000000     4.567251        0.721450   \n",
       "145            213         7.166667     3.744186        0.082990   \n",
       "146            427        11.285714     4.171053        0.866562   \n",
       "162           1359        18.307692     4.670996        0.845897   \n",
       "168            292        18.666667     4.053571        0.021653   \n",
       "175           5240        20.928571     4.867206        0.685279   \n",
       "176           6550        20.245283     5.044933        0.437458   \n",
       "178            760        11.250000     4.451128        0.794493   \n",
       "229            740        14.555556     4.589147        0.774136   \n",
       "284            256        16.333333     4.142857        0.603476   \n",
       "288            783        20.000000     4.467153        0.271698   \n",
       "312            888        15.363636     4.197605        0.666079   \n",
       "343           1819        29.363636     4.520249        0.812502   \n",
       "363            377        12.000000     4.171429        0.412172   \n",
       "364           1717        17.500000     4.355987        0.700787   \n",
       "381            737        12.400000     4.701613        0.424206   \n",
       "396            437        12.285714     3.964706        0.528682   \n",
       "402           2645        15.933333     4.457627        0.830432   \n",
       "413           1439        16.800000     4.560000        0.751769   \n",
       "435            749        13.777778     5.008264        0.683476   \n",
       "476           4161        27.400000     5.022189        0.841326   \n",
       "494           3363        20.533333     4.468908        0.862231   \n",
       "\n",
       "     Helpful_Rating_2  \n",
       "14          12.902213  \n",
       "18           0.598067  \n",
       "19           0.598067  \n",
       "35           1.117680  \n",
       "36          -9.622513  \n",
       "41           0.598067  \n",
       "48          -8.102900  \n",
       "49          20.760086  \n",
       "50           2.196133  \n",
       "56          47.858433  \n",
       "60          32.387713  \n",
       "61         -41.450827  \n",
       "63         -10.725413  \n",
       "67           0.495167  \n",
       "69          -7.102900  \n",
       "70           0.637293  \n",
       "71           1.117680  \n",
       "75           1.117680  \n",
       "76           0.897100  \n",
       "77         -19.985220  \n",
       "82           4.313813  \n",
       "90         -43.225134  \n",
       "97          -0.622513  \n",
       "114          0.676520  \n",
       "116        -18.607733  \n",
       "120          1.416713  \n",
       "130          3.897100  \n",
       "133          2.598067  \n",
       "137          0.857873  \n",
       "145        -13.063673  \n",
       "146          3.156907  \n",
       "162          2.857873  \n",
       "168         -8.142127  \n",
       "175         -0.583287  \n",
       "176         -7.544060  \n",
       "178         -0.269474  \n",
       "229          1.857873  \n",
       "284         -0.882320  \n",
       "288         -5.142127  \n",
       "312          0.117680  \n",
       "343          2.196133  \n",
       "363         -9.024447  \n",
       "364         -1.284253  \n",
       "381         -6.323480  \n",
       "396         -4.803867  \n",
       "402          2.676520  \n",
       "413         -0.245027  \n",
       "435          0.598067  \n",
       "476          3.171687  \n",
       "494          4.392267  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>Review_Length</th>\n",
       "      <th>Sentence_Length</th>\n",
       "      <th>Word_Length</th>\n",
       "      <th>Helpful_Rating</th>\n",
       "      <th>Helpful_Rating_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>787981.000000</td>\n",
       "      <td>787981.000000</td>\n",
       "      <td>787981.000000</td>\n",
       "      <td>787981.000000</td>\n",
       "      <td>787981.000000</td>\n",
       "      <td>787981.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.621601</td>\n",
       "      <td>1591.897915</td>\n",
       "      <td>17.967505</td>\n",
       "      <td>4.594298</td>\n",
       "      <td>0.715281</td>\n",
       "      <td>0.302807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.526728</td>\n",
       "      <td>1576.932201</td>\n",
       "      <td>6.397815</td>\n",
       "      <td>0.391554</td>\n",
       "      <td>0.213207</td>\n",
       "      <td>18.045332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.602484</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.021653</td>\n",
       "      <td>-1078.990413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>591.000000</td>\n",
       "      <td>13.916667</td>\n",
       "      <td>4.340741</td>\n",
       "      <td>0.608302</td>\n",
       "      <td>-2.362707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1145.000000</td>\n",
       "      <td>17.266667</td>\n",
       "      <td>4.582734</td>\n",
       "      <td>0.776986</td>\n",
       "      <td>1.598067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>2068.000000</td>\n",
       "      <td>21.142857</td>\n",
       "      <td>4.835052</td>\n",
       "      <td>0.874423</td>\n",
       "      <td>3.848206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>32658.000000</td>\n",
       "      <td>591.000000</td>\n",
       "      <td>52.666667</td>\n",
       "      <td>0.999320</td>\n",
       "      <td>5389.438921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             overall  Review_Length  Sentence_Length    Word_Length  \\\n",
       "count  787981.000000  787981.000000    787981.000000  787981.000000   \n",
       "mean        3.621601    1591.897915        17.967505       4.594298   \n",
       "std         1.526728    1576.932201         6.397815       0.391554   \n",
       "min         1.000000       4.000000         0.602484       1.000000   \n",
       "25%         2.000000     591.000000        13.916667       4.340741   \n",
       "50%         4.000000    1145.000000        17.266667       4.582734   \n",
       "75%         5.000000    2068.000000        21.142857       4.835052   \n",
       "max         5.000000   32658.000000       591.000000      52.666667   \n",
       "\n",
       "       Helpful_Rating  Helpful_Rating_2  \n",
       "count   787981.000000     787981.000000  \n",
       "mean         0.715281          0.302807  \n",
       "std          0.213207         18.045332  \n",
       "min          0.021653      -1078.990413  \n",
       "25%          0.608302         -2.362707  \n",
       "50%          0.776986          1.598067  \n",
       "75%          0.874423          3.848206  \n",
       "max          0.999320       5389.438921  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This book was a philosophical touchstone for insecure Boomers of the mid-1970s. Everybody I knew in those days had to be able to discuss it intelligently or risk being thought to have a gap in our characters as people. A folk/ talking blues singer of that era (I forget who) referred to this book in a lyric:\"...a copy of Kahlil Gibran\\'s \\'The Prophet\\' with all the significant passages highlighted--the whole damn BOOK was highlited...\"In truth, the whole phenomenon was symptomatic of the societal immaturity of my generation as young adults. It taught us all sorts of theoretical concepts of human nature that were not necessarily reflective of the real world--consideration, the dignity of each person, peace, love, repudiation of prejudice--all of this in a world that anything but reflected such beliefs in Gibran\\'s day. And except for the hippy-dippy pseudo-enlightenment we tried to cram down the world\\'s throat in our day, our peculiar era was no better. We just used Gibran and other such philosophers to peer-pressure one another into self-defeating meekness. If someone you knew was erudite enough to understand philosophy but didn\\'t have the moxie to stand up to people when he should, Gibran was the ideal way to make him a bona fide doormat and make him think he liked it. I won\\'t even try to speculate how \"relevant\" Gibran is nowadays. From the perspective of a sadder but wiser man--or at least not quite as stupid--I give you this Sting lyric from the song \"Consider Me Gone\" for consideration:\"To search for perfectionIs all very wellBut to wait for HeavenIs to live here in Hell\"'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[90,'reviewText']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_pick_percentage = True\n",
    "\n",
    "if hand_pick_percentage:\n",
    "    high = 0.85\n",
    "    low = 0.50\n",
    "else:\n",
    "    high = df['Helpful_Rating'].median + MIDDLEPERCENTAGE*0.25\n",
    "    low = df['Helpful_Rating'].median - MIDDLEPERCENTAGE*0.75\n",
    "\n",
    "df_adjusted = df[(df['Helpful_Rating']<low) | (df['Helpful_Rating']>high)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>helpful</th>\n",
       "      <th>Review_Length</th>\n",
       "      <th>Sentence_Length</th>\n",
       "      <th>Word_Length</th>\n",
       "      <th>Helpful_Rating</th>\n",
       "      <th>Helpful_Rating_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>This is one of the first (literary) books I re...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[81, 92]</td>\n",
       "      <td>1542</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>4.258865</td>\n",
       "      <td>0.902674</td>\n",
       "      <td>12.902213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>I evidently misread the writeup, I thought it ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[0, 13]</td>\n",
       "      <td>178</td>\n",
       "      <td>11.666667</td>\n",
       "      <td>3.885714</td>\n",
       "      <td>0.021653</td>\n",
       "      <td>-9.622513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Maybe I just wasn't in the right mood for a he...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[3, 15]</td>\n",
       "      <td>885</td>\n",
       "      <td>13.076923</td>\n",
       "      <td>4.059880</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>-8.102900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Gibran gets right down to the bedrock of what ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[97, 103]</td>\n",
       "      <td>931</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>4.257310</td>\n",
       "      <td>0.944421</td>\n",
       "      <td>20.760086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>A prophet has waited twelve years in a coastal...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[207, 215]</td>\n",
       "      <td>2048</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>4.354054</td>\n",
       "      <td>0.962563</td>\n",
       "      <td>47.858433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>I first became aware of Kahlil Gibran when I r...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[156, 167]</td>\n",
       "      <td>883</td>\n",
       "      <td>16.200000</td>\n",
       "      <td>4.260870</td>\n",
       "      <td>0.943198</td>\n",
       "      <td>32.387713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>I appreciate getting the book at the great pri...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0, 56]</td>\n",
       "      <td>219</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.307692</td>\n",
       "      <td>0.021653</td>\n",
       "      <td>-41.450827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>I picked up this book after being inspired by ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[10, 28]</td>\n",
       "      <td>234</td>\n",
       "      <td>14.666667</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>0.443169</td>\n",
       "      <td>-10.725413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>I originally read this early in college and di...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[4, 15]</td>\n",
       "      <td>388</td>\n",
       "      <td>13.600000</td>\n",
       "      <td>4.727273</td>\n",
       "      <td>0.296945</td>\n",
       "      <td>-7.102900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>This man was a son of a pastor, but worshipped...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0, 27]</td>\n",
       "      <td>1120</td>\n",
       "      <td>24.142857</td>\n",
       "      <td>5.140244</td>\n",
       "      <td>0.021653</td>\n",
       "      <td>-19.985220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>I am alive like you, and I am standing beside ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[28, 32]</td>\n",
       "      <td>3309</td>\n",
       "      <td>20.655172</td>\n",
       "      <td>4.511945</td>\n",
       "      <td>0.873456</td>\n",
       "      <td>4.313813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>\"The Prophet\" is Almustafa, called \"the chosen...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[11, 40]</td>\n",
       "      <td>4291</td>\n",
       "      <td>18.925000</td>\n",
       "      <td>4.456724</td>\n",
       "      <td>0.406507</td>\n",
       "      <td>-18.607733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>At first, I was going to tick Beryl Bainbridge...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[15, 15]</td>\n",
       "      <td>2371</td>\n",
       "      <td>16.833333</td>\n",
       "      <td>4.579208</td>\n",
       "      <td>0.897752</td>\n",
       "      <td>3.897100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>I didn't realize this was the children's book ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1, 19]</td>\n",
       "      <td>213</td>\n",
       "      <td>7.166667</td>\n",
       "      <td>3.744186</td>\n",
       "      <td>0.082990</td>\n",
       "      <td>-13.063673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Beginning with &amp;quot;The first six words I'll ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[15, 16]</td>\n",
       "      <td>427</td>\n",
       "      <td>11.285714</td>\n",
       "      <td>4.171053</td>\n",
       "      <td>0.866562</td>\n",
       "      <td>3.156907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>I ordered this book through one of Amazon Mark...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[0, 11]</td>\n",
       "      <td>292</td>\n",
       "      <td>18.666667</td>\n",
       "      <td>4.053571</td>\n",
       "      <td>0.021653</td>\n",
       "      <td>-8.142127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>I bought this book based on two 5 star custome...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[8, 21]</td>\n",
       "      <td>6550</td>\n",
       "      <td>20.245283</td>\n",
       "      <td>5.044933</td>\n",
       "      <td>0.437458</td>\n",
       "      <td>-7.544060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>I was extremely happy with every aspect of thi...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[3, 11]</td>\n",
       "      <td>783</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>4.467153</td>\n",
       "      <td>0.271698</td>\n",
       "      <td>-5.142127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>I really wish publishers would rate books like...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[8, 23]</td>\n",
       "      <td>377</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>4.171429</td>\n",
       "      <td>0.412172</td>\n",
       "      <td>-9.024447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>This really is an excellent book with an inter...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[7, 18]</td>\n",
       "      <td>737</td>\n",
       "      <td>12.400000</td>\n",
       "      <td>4.701613</td>\n",
       "      <td>0.424206</td>\n",
       "      <td>-6.323480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>Have to say I'm wondering what all the fuss is...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[34, 40]</td>\n",
       "      <td>3363</td>\n",
       "      <td>20.533333</td>\n",
       "      <td>4.468908</td>\n",
       "      <td>0.862231</td>\n",
       "      <td>4.392267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>The archetypical American novel features a sol...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[6, 13]</td>\n",
       "      <td>3920</td>\n",
       "      <td>26.041667</td>\n",
       "      <td>5.160454</td>\n",
       "      <td>0.455193</td>\n",
       "      <td>-3.622513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>Not that I wanted to know anything about the c...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[6, 12]</td>\n",
       "      <td>1538</td>\n",
       "      <td>19.333333</td>\n",
       "      <td>4.280142</td>\n",
       "      <td>0.478270</td>\n",
       "      <td>-2.882320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>Although it is only April, I predict that Wate...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[362, 394]</td>\n",
       "      <td>2461</td>\n",
       "      <td>18.739130</td>\n",
       "      <td>4.569087</td>\n",
       "      <td>0.933643</td>\n",
       "      <td>70.363825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>like many others, i was disappointed by the di...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[7, 14]</td>\n",
       "      <td>279</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>4.913043</td>\n",
       "      <td>0.490873</td>\n",
       "      <td>-3.362707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>This wonderful book shot through the family li...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[22, 23]</td>\n",
       "      <td>1457</td>\n",
       "      <td>30.750000</td>\n",
       "      <td>4.792683</td>\n",
       "      <td>0.903429</td>\n",
       "      <td>4.975553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>This book was easy reading, but was also kind ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[34, 40]</td>\n",
       "      <td>404</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>4.402778</td>\n",
       "      <td>0.862231</td>\n",
       "      <td>4.392267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>I agree with several other people who found it...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[6, 14]</td>\n",
       "      <td>571</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.435413</td>\n",
       "      <td>-4.362707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>I managed to read half the book and then could...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[4, 13]</td>\n",
       "      <td>201</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>3.950000</td>\n",
       "      <td>0.321480</td>\n",
       "      <td>-5.622513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>I am not a big fan of books on tape.  My husba...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[3, 12]</td>\n",
       "      <td>441</td>\n",
       "      <td>8.700000</td>\n",
       "      <td>3.929412</td>\n",
       "      <td>0.258062</td>\n",
       "      <td>-5.882320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>I purchased this because I read good reviews a...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[6, 13]</td>\n",
       "      <td>175</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>4.181818</td>\n",
       "      <td>0.455193</td>\n",
       "      <td>-3.622513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>I had heard this was a good book.  I was misin...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[4, 16]</td>\n",
       "      <td>646</td>\n",
       "      <td>12.888889</td>\n",
       "      <td>4.396552</td>\n",
       "      <td>0.286864</td>\n",
       "      <td>-7.843093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>I'm another reader who can't even begin to und...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[6, 15]</td>\n",
       "      <td>427</td>\n",
       "      <td>18.250000</td>\n",
       "      <td>4.575342</td>\n",
       "      <td>0.418270</td>\n",
       "      <td>-5.102900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>I lost the plot somewhere between the strip sc...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[4, 11]</td>\n",
       "      <td>151</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>0.355046</td>\n",
       "      <td>-4.142127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>As a small town child,I always loooked forward...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[6, 17]</td>\n",
       "      <td>479</td>\n",
       "      <td>16.800000</td>\n",
       "      <td>4.887500</td>\n",
       "      <td>0.390035</td>\n",
       "      <td>-6.583287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1157</th>\n",
       "      <td>So, this is the dreck that is passing for 'mod...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[5, 11]</td>\n",
       "      <td>2764</td>\n",
       "      <td>19.576923</td>\n",
       "      <td>4.342052</td>\n",
       "      <td>0.438395</td>\n",
       "      <td>-3.142127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1188</th>\n",
       "      <td>I loved this book.  It was sometimes hard to r...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[3, 11]</td>\n",
       "      <td>560</td>\n",
       "      <td>15.142857</td>\n",
       "      <td>4.056604</td>\n",
       "      <td>0.271698</td>\n",
       "      <td>-5.142127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1192</th>\n",
       "      <td>I found this book interesting because of the r...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[216, 258]</td>\n",
       "      <td>3439</td>\n",
       "      <td>19.281250</td>\n",
       "      <td>4.432079</td>\n",
       "      <td>0.883500</td>\n",
       "      <td>25.030119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>I purchased this book because it received grea...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[6, 15]</td>\n",
       "      <td>445</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>4.851351</td>\n",
       "      <td>0.418270</td>\n",
       "      <td>-5.102900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>I've decided I just can't finish this book. Th...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[3, 13]</td>\n",
       "      <td>726</td>\n",
       "      <td>26.200000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>0.246523</td>\n",
       "      <td>-6.622513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1313</th>\n",
       "      <td>In recent years, publishers have put out a num...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[238, 285]</td>\n",
       "      <td>1711</td>\n",
       "      <td>19.357143</td>\n",
       "      <td>5.275472</td>\n",
       "      <td>0.882765</td>\n",
       "      <td>27.044899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357</th>\n",
       "      <td>I bought this book because it was rated so hig...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[4, 14]</td>\n",
       "      <td>528</td>\n",
       "      <td>17.833333</td>\n",
       "      <td>3.841121</td>\n",
       "      <td>0.308293</td>\n",
       "      <td>-6.362707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382</th>\n",
       "      <td>WE was terrific out of the starting blocks, vi...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[5, 13]</td>\n",
       "      <td>977</td>\n",
       "      <td>19.625000</td>\n",
       "      <td>5.006410</td>\n",
       "      <td>0.396437</td>\n",
       "      <td>-4.622513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>I didn't get into the characters at all, I ski...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[4, 10]</td>\n",
       "      <td>96</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>3.947368</td>\n",
       "      <td>0.376864</td>\n",
       "      <td>-3.401933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1412</th>\n",
       "      <td>What a terrific read! Water for Elephants has ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[1515, 1581]</td>\n",
       "      <td>1295</td>\n",
       "      <td>19.636364</td>\n",
       "      <td>4.855140</td>\n",
       "      <td>0.960740</td>\n",
       "      <td>344.754334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>Stripped of everything after his parents' unti...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[1071, 1150]</td>\n",
       "      <td>2971</td>\n",
       "      <td>30.937500</td>\n",
       "      <td>4.876268</td>\n",
       "      <td>0.943402</td>\n",
       "      <td>219.777662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>Life behind the scenes at the circus was crude...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[3, 12]</td>\n",
       "      <td>297</td>\n",
       "      <td>10.400000</td>\n",
       "      <td>4.627451</td>\n",
       "      <td>0.258062</td>\n",
       "      <td>-5.882320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1639</th>\n",
       "      <td>I would have given this book no stars but that...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[5, 13]</td>\n",
       "      <td>202</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>4.378378</td>\n",
       "      <td>0.396437</td>\n",
       "      <td>-4.622513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734</th>\n",
       "      <td>As a devoted historical fiction reader, I thou...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[140, 173]</td>\n",
       "      <td>880</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>4.577922</td>\n",
       "      <td>0.864867</td>\n",
       "      <td>11.946553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1809</th>\n",
       "      <td>Water for Elephants is told by and about Jacob...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[73, 77]</td>\n",
       "      <td>1089</td>\n",
       "      <td>22.375000</td>\n",
       "      <td>5.051136</td>\n",
       "      <td>0.939317</td>\n",
       "      <td>16.005113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviewText  overall  \\\n",
       "14    This is one of the first (literary) books I re...      5.0   \n",
       "36    I evidently misread the writeup, I thought it ...      2.0   \n",
       "48    Maybe I just wasn't in the right mood for a he...      3.0   \n",
       "49    Gibran gets right down to the bedrock of what ...      5.0   \n",
       "56    A prophet has waited twelve years in a coastal...      5.0   \n",
       "60    I first became aware of Kahlil Gibran when I r...      4.0   \n",
       "61    I appreciate getting the book at the great pri...      1.0   \n",
       "63    I picked up this book after being inspired by ...      2.0   \n",
       "69    I originally read this early in college and di...      3.0   \n",
       "77    This man was a son of a pastor, but worshipped...      1.0   \n",
       "82    I am alive like you, and I am standing beside ...      5.0   \n",
       "116   \"The Prophet\" is Almustafa, called \"the chosen...      1.0   \n",
       "130   At first, I was going to tick Beryl Bainbridge...      4.0   \n",
       "145   I didn't realize this was the children's book ...      1.0   \n",
       "146   Beginning with &quot;The first six words I'll ...      5.0   \n",
       "168   I ordered this book through one of Amazon Mark...      3.0   \n",
       "176   I bought this book based on two 5 star custome...      2.0   \n",
       "288   I was extremely happy with every aspect of thi...      4.0   \n",
       "363   I really wish publishers would rate books like...      1.0   \n",
       "381   This really is an excellent book with an inter...      3.0   \n",
       "494   Have to say I'm wondering what all the fuss is...      3.0   \n",
       "503   The archetypical American novel features a sol...      5.0   \n",
       "606   Not that I wanted to know anything about the c...      3.0   \n",
       "675   Although it is only April, I predict that Wate...      5.0   \n",
       "686   like many others, i was disappointed by the di...      1.0   \n",
       "705   This wonderful book shot through the family li...      5.0   \n",
       "796   This book was easy reading, but was also kind ...      2.0   \n",
       "800   I agree with several other people who found it...      1.0   \n",
       "860   I managed to read half the book and then could...      1.0   \n",
       "912   I am not a big fan of books on tape.  My husba...      1.0   \n",
       "963   I purchased this because I read good reviews a...      1.0   \n",
       "997   I had heard this was a good book.  I was misin...      1.0   \n",
       "1059  I'm another reader who can't even begin to und...      1.0   \n",
       "1092  I lost the plot somewhere between the strip sc...      1.0   \n",
       "1140  As a small town child,I always loooked forward...      2.0   \n",
       "1157  So, this is the dreck that is passing for 'mod...      2.0   \n",
       "1188  I loved this book.  It was sometimes hard to r...      5.0   \n",
       "1192  I found this book interesting because of the r...      3.0   \n",
       "1195  I purchased this book because it received grea...      2.0   \n",
       "1283  I've decided I just can't finish this book. Th...      1.0   \n",
       "1313  In recent years, publishers have put out a num...      3.0   \n",
       "1357  I bought this book because it was rated so hig...      1.0   \n",
       "1382  WE was terrific out of the starting blocks, vi...      3.0   \n",
       "1383  I didn't get into the characters at all, I ski...      1.0   \n",
       "1412  What a terrific read! Water for Elephants has ...      5.0   \n",
       "1451  Stripped of everything after his parents' unti...      5.0   \n",
       "1513  Life behind the scenes at the circus was crude...      2.0   \n",
       "1639  I would have given this book no stars but that...      1.0   \n",
       "1734  As a devoted historical fiction reader, I thou...      1.0   \n",
       "1809  Water for Elephants is told by and about Jacob...      5.0   \n",
       "\n",
       "           helpful  Review_Length  Sentence_Length  Word_Length  \\\n",
       "14        [81, 92]           1542        15.000000     4.258865   \n",
       "36         [0, 13]            178        11.666667     3.885714   \n",
       "48         [3, 15]            885        13.076923     4.059880   \n",
       "49       [97, 103]            931        19.000000     4.257310   \n",
       "56      [207, 215]           2048        17.500000     4.354054   \n",
       "60      [156, 167]            883        16.200000     4.260870   \n",
       "61         [0, 56]            219        10.000000     4.307692   \n",
       "63        [10, 28]            234        14.666667     4.250000   \n",
       "69         [4, 15]            388        13.600000     4.727273   \n",
       "77         [0, 27]           1120        24.142857     5.140244   \n",
       "82        [28, 32]           3309        20.655172     4.511945   \n",
       "116       [11, 40]           4291        18.925000     4.456724   \n",
       "130       [15, 15]           2371        16.833333     4.579208   \n",
       "145        [1, 19]            213         7.166667     3.744186   \n",
       "146       [15, 16]            427        11.285714     4.171053   \n",
       "168        [0, 11]            292        18.666667     4.053571   \n",
       "176        [8, 21]           6550        20.245283     5.044933   \n",
       "288        [3, 11]            783        20.000000     4.467153   \n",
       "363        [8, 23]            377        12.000000     4.171429   \n",
       "381        [7, 18]            737        12.400000     4.701613   \n",
       "494       [34, 40]           3363        20.533333     4.468908   \n",
       "503        [6, 13]           3920        26.041667     5.160454   \n",
       "606        [6, 12]           1538        19.333333     4.280142   \n",
       "675     [362, 394]           2461        18.739130     4.569087   \n",
       "686        [7, 14]            279         9.400000     4.913043   \n",
       "705       [22, 23]           1457        30.750000     4.792683   \n",
       "796       [34, 40]            404        24.000000     4.402778   \n",
       "800        [6, 14]            571        18.500000     4.000000   \n",
       "860        [4, 13]            201        13.333333     3.950000   \n",
       "912        [3, 12]            441         8.700000     3.929412   \n",
       "963        [6, 13]            175         8.250000     4.181818   \n",
       "997        [4, 16]            646        12.888889     4.396552   \n",
       "1059       [6, 15]            427        18.250000     4.575342   \n",
       "1092       [4, 11]            151        14.000000     4.250000   \n",
       "1140       [6, 17]            479        16.800000     4.887500   \n",
       "1157       [5, 11]           2764        19.576923     4.342052   \n",
       "1188       [3, 11]            560        15.142857     4.056604   \n",
       "1192    [216, 258]           3439        19.281250     4.432079   \n",
       "1195       [6, 15]            445        15.000000     4.851351   \n",
       "1283       [3, 13]            726        26.200000     4.400000   \n",
       "1313    [238, 285]           1711        19.357143     5.275472   \n",
       "1357       [4, 14]            528        17.833333     3.841121   \n",
       "1382       [5, 13]            977        19.625000     5.006410   \n",
       "1383       [4, 10]             96        19.000000     3.947368   \n",
       "1412  [1515, 1581]           1295        19.636364     4.855140   \n",
       "1451  [1071, 1150]           2971        30.937500     4.876268   \n",
       "1513       [3, 12]            297        10.400000     4.627451   \n",
       "1639       [5, 13]            202         9.500000     4.378378   \n",
       "1734    [140, 173]            880        15.500000     4.577922   \n",
       "1809      [73, 77]           1089        22.375000     5.051136   \n",
       "\n",
       "      Helpful_Rating  Helpful_Rating_2  \n",
       "14          0.902674         12.902213  \n",
       "36          0.021653         -9.622513  \n",
       "48          0.228122         -8.102900  \n",
       "49          0.944421         20.760086  \n",
       "56          0.962563         47.858433  \n",
       "60          0.943198         32.387713  \n",
       "61          0.021653        -41.450827  \n",
       "63          0.443169        -10.725413  \n",
       "69          0.296945         -7.102900  \n",
       "77          0.021653        -19.985220  \n",
       "82          0.873456          4.313813  \n",
       "116         0.406507        -18.607733  \n",
       "130         0.897752          3.897100  \n",
       "145         0.082990        -13.063673  \n",
       "146         0.866562          3.156907  \n",
       "168         0.021653         -8.142127  \n",
       "176         0.437458         -7.544060  \n",
       "288         0.271698         -5.142127  \n",
       "363         0.412172         -9.024447  \n",
       "381         0.424206         -6.323480  \n",
       "494         0.862231          4.392267  \n",
       "503         0.455193         -3.622513  \n",
       "606         0.478270         -2.882320  \n",
       "675         0.933643         70.363825  \n",
       "686         0.490873         -3.362707  \n",
       "705         0.903429          4.975553  \n",
       "796         0.862231          4.392267  \n",
       "800         0.435413         -4.362707  \n",
       "860         0.321480         -5.622513  \n",
       "912         0.258062         -5.882320  \n",
       "963         0.455193         -3.622513  \n",
       "997         0.286864         -7.843093  \n",
       "1059        0.418270         -5.102900  \n",
       "1092        0.355046         -4.142127  \n",
       "1140        0.390035         -6.583287  \n",
       "1157        0.438395         -3.142127  \n",
       "1188        0.271698         -5.142127  \n",
       "1192        0.883500         25.030119  \n",
       "1195        0.418270         -5.102900  \n",
       "1283        0.246523         -6.622513  \n",
       "1313        0.882765         27.044899  \n",
       "1357        0.308293         -6.362707  \n",
       "1382        0.396437         -4.622513  \n",
       "1383        0.376864         -3.401933  \n",
       "1412        0.960740        344.754334  \n",
       "1451        0.943402        219.777662  \n",
       "1513        0.258062         -5.882320  \n",
       "1639        0.396437         -4.622513  \n",
       "1734        0.864867         11.946553  \n",
       "1809        0.939317         16.005113  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_adjusted.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewText          380007\n",
       "overall             380007\n",
       "helpful             380007\n",
       "Review_Length       380007\n",
       "Sentence_Length     380007\n",
       "Word_Length         380007\n",
       "Helpful_Rating      380007\n",
       "Helpful_Rating_2    380007\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_adjusted.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def helpful(row):\n",
    "    if row['Helpful_Rating']>high:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_adjusted['Helpful'] = df_adjusted.apply(helpful, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>helpful</th>\n",
       "      <th>Review_Length</th>\n",
       "      <th>Sentence_Length</th>\n",
       "      <th>Word_Length</th>\n",
       "      <th>Helpful_Rating</th>\n",
       "      <th>Helpful_Rating_2</th>\n",
       "      <th>Helpful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>This is one of the first (literary) books I re...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[81, 92]</td>\n",
       "      <td>1542</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>4.258865</td>\n",
       "      <td>0.902674</td>\n",
       "      <td>12.902213</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>I evidently misread the writeup, I thought it ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[0, 13]</td>\n",
       "      <td>178</td>\n",
       "      <td>11.666667</td>\n",
       "      <td>3.885714</td>\n",
       "      <td>0.021653</td>\n",
       "      <td>-9.622513</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Maybe I just wasn't in the right mood for a he...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[3, 15]</td>\n",
       "      <td>885</td>\n",
       "      <td>13.076923</td>\n",
       "      <td>4.059880</td>\n",
       "      <td>0.228122</td>\n",
       "      <td>-8.102900</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Gibran gets right down to the bedrock of what ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[97, 103]</td>\n",
       "      <td>931</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>4.257310</td>\n",
       "      <td>0.944421</td>\n",
       "      <td>20.760086</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>A prophet has waited twelve years in a coastal...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[207, 215]</td>\n",
       "      <td>2048</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>4.354054</td>\n",
       "      <td>0.962563</td>\n",
       "      <td>47.858433</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           reviewText  overall     helpful  \\\n",
       "14  This is one of the first (literary) books I re...      5.0    [81, 92]   \n",
       "36  I evidently misread the writeup, I thought it ...      2.0     [0, 13]   \n",
       "48  Maybe I just wasn't in the right mood for a he...      3.0     [3, 15]   \n",
       "49  Gibran gets right down to the bedrock of what ...      5.0   [97, 103]   \n",
       "56  A prophet has waited twelve years in a coastal...      5.0  [207, 215]   \n",
       "\n",
       "    Review_Length  Sentence_Length  Word_Length  Helpful_Rating  \\\n",
       "14           1542        15.000000     4.258865        0.902674   \n",
       "36            178        11.666667     3.885714        0.021653   \n",
       "48            885        13.076923     4.059880        0.228122   \n",
       "49            931        19.000000     4.257310        0.944421   \n",
       "56           2048        17.500000     4.354054        0.962563   \n",
       "\n",
       "    Helpful_Rating_2  Helpful  \n",
       "14         12.902213        1  \n",
       "36         -9.622513        0  \n",
       "48         -8.102900        0  \n",
       "49         20.760086        1  \n",
       "56         47.858433        1  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_adjusted.head()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_set = df_adjusted[['reviewText', 'Helpful']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_adjusted['reviewText']\n",
    "y = df_adjusted['Helpful']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def make_xy(df, vectorizer=None):\n",
    "    #Your code here    \n",
    "    if vectorizer is None:\n",
    "        vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(df.reviewText)\n",
    "    X = X.tocsc()  # some versions of sklearn return COO format\n",
    "    y = df.Helpful\n",
    "    return X, y\n",
    "\n",
    "# Declare X and y\n",
    "X, y = make_xy(df_adjusted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your turn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Split into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# Create a multinomial classifier\n",
    "clf = MultinomialNB()\n",
    "\n",
    "# Fit the classifier to the data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Print the accuracy\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[38404 11617]\n",
      " [13108 88874]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.77      0.76     50021\n",
      "          1       0.88      0.87      0.88    101982\n",
      "\n",
      "avg / total       0.84      0.84      0.84    152003\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary modules\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state=42)\n",
    "\n",
    "# Create the classifier: logreg\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test set: y_pred\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Compute and print the confusion matrix and classification report\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.891429620269024\n",
      "AUC scores computed using 5-fold cross-validation: [0.88828643 0.85705656 0.88397178 0.87036848 0.89180698]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Compute predicted probabilities: y_pred_prob\n",
    "y_pred_prob = logreg.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Compute and print AUC score\n",
    "print(\"AUC: {}\".format(roc_auc_score(y_test, y_pred_prob)))\n",
    "\n",
    "# Compute cross-validated AUC scores: cv_auc\n",
    "cv_auc = cross_val_score(logreg, X, y, cv=5, scoring='roc_auc')\n",
    "\n",
    "# Print list of AUC scores\n",
    "print(\"AUC scores computed using 5-fold cross-validation: {}\".format(cv_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Setup the hyperparameter grid\n",
    "c_space = np.logspace(-5, 8, 15)\n",
    "param_grid = {'C': c_space}\n",
    "\n",
    "# Instantiate a logistic regression classifier: logreg\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Instantiate the GridSearchCV object: logreg_cv\n",
    "logreg_cv = GridSearchCV(logreg, param_grid, cv=5)\n",
    "\n",
    "# Fit it to the data\n",
    "logreg_cv.fit(X,y)\n",
    "\n",
    "# Print the tuned parameters and score\n",
    "print(\"Tuned Logistic Regression Parameters: {}\".format(logreg_cv.best_params_)) \n",
    "print(\"Best score is {}\".format(logreg_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from scipy.stats import randint\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Setup the parameters and distributions to sample from: param_dist\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"max_features\": randint(1, 9),\n",
    "              \"min_samples_leaf\": randint(1, 9),\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# Instantiate a Decision Tree classifier: tree\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object: tree_cv\n",
    "tree_cv = RandomizedSearchCV(tree, param_dist, cv=5)\n",
    "\n",
    "# Fit it to the data\n",
    "tree_cv.fit(X,y)\n",
    "\n",
    "# Print the tuned parameters and score\n",
    "print(\"Tuned Decision Tree Parameters: {}\".format(tree_cv.best_params_))\n",
    "print(\"Best score is {}\".format(tree_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from scipy.stats import randint\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Setup the parameters and distributions to sample from: param_dist\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"max_features\": randint(1, 9),\n",
    "              \"min_samples_leaf\": randint(1, 9),\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# Instantiate a Decision Tree classifier: tree\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object: tree_cv\n",
    "tree_cv = RandomizedSearchCV(tree, param_dist, cv=5)\n",
    "\n",
    "# Fit it to the data\n",
    "tree_cv.fit(X,y)\n",
    "\n",
    "# Print the tuned parameters and score\n",
    "print(\"Tuned Decision Tree Parameters: {}\".format(tree_cv.best_params_))\n",
    "print(\"Best score is {}\".format(tree_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/coreyjwade/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "corpus = df_adjusted['reviewText']\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "nltk.download('stopwords')\n",
    "\n",
    "wpt = nltk.WordPunctTokenizer()\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def normalize_document(doc):\n",
    "    # lower case and remove special characters\\whitespaces\n",
    "    doc = re.sub(r'[^a-zA-Z\\s]', '', doc, re.I|re.A)\n",
    "    doc = doc.lower()\n",
    "    doc = doc.strip()\n",
    "    # tokenize document\n",
    "    tokens = wpt.tokenize(doc)\n",
    "    # filter stopwords out of document\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    # re-create document from filtered tokens\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    return doc\n",
    "\n",
    "normalize_corpus = np.vectorize(normalize_document)\n",
    "norm_corpus = normalize_corpus(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorizer as Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>Review_Length</th>\n",
       "      <th>Sentence_Length</th>\n",
       "      <th>Word_Length</th>\n",
       "      <th>Helpful_Rating</th>\n",
       "      <th>Badge</th>\n",
       "      <th>CountVectorizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is one of the first (...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1542</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>4.258865</td>\n",
       "      <td>0.902674</td>\n",
       "      <td>Gold</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Prophet is Kahlil Gibr...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2294</td>\n",
       "      <td>22.705882</td>\n",
       "      <td>4.883289</td>\n",
       "      <td>0.683638</td>\n",
       "      <td>Approved</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gibran Khalil Gibran was b...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>712</td>\n",
       "      <td>19.428571</td>\n",
       "      <td>4.103704</td>\n",
       "      <td>0.683638</td>\n",
       "      <td>Approved</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Certainly the words are of...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>700</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>4.675000</td>\n",
       "      <td>0.728884</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I evidently misread the wr...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>178</td>\n",
       "      <td>11.666667</td>\n",
       "      <td>3.885714</td>\n",
       "      <td>0.021653</td>\n",
       "      <td>Questionable</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      reviewText  overall  Review_Length  Sentence_Length  \\\n",
       "0  This is one of the first (...      5.0           1542        15.000000   \n",
       "1  The Prophet is Kahlil Gibr...      5.0           2294        22.705882   \n",
       "2  Gibran Khalil Gibran was b...      5.0            712        19.428571   \n",
       "3  Certainly the words are of...      5.0            700        21.000000   \n",
       "4  I evidently misread the wr...      2.0            178        11.666667   \n",
       "\n",
       "   Word_Length  Helpful_Rating         Badge                CountVectorizer  \n",
       "0     4.258865        0.902674          Gold  [0, 0, 0, 0, 0, 0, 0, 0, 0...  \n",
       "1     4.883289        0.683638      Approved  [0, 0, 0, 0, 0, 0, 0, 0, 0...  \n",
       "2     4.103704        0.683638      Approved  [0, 0, 0, 0, 0, 0, 0, 0, 0...  \n",
       "3     4.675000        0.728884        Bronze  [0, 0, 0, 0, 0, 0, 0, 0, 0...  \n",
       "4     3.885714        0.021653  Questionable  [0, 0, 0, 0, 0, 0, 0, 0, 0...  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer().fit_transform(norm_corpus) \n",
    "df['CountVectorizer'] = list(vect.toarray())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigram as Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>Review_Length</th>\n",
       "      <th>Sentence_Length</th>\n",
       "      <th>Word_Length</th>\n",
       "      <th>Helpful_Rating</th>\n",
       "      <th>Badge</th>\n",
       "      <th>CountVectorizer</th>\n",
       "      <th>Bigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is one of the first (...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1542</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>4.258865</td>\n",
       "      <td>0.902674</td>\n",
       "      <td>Gold</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Prophet is Kahlil Gibr...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2294</td>\n",
       "      <td>22.705882</td>\n",
       "      <td>4.883289</td>\n",
       "      <td>0.683638</td>\n",
       "      <td>Approved</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gibran Khalil Gibran was b...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>712</td>\n",
       "      <td>19.428571</td>\n",
       "      <td>4.103704</td>\n",
       "      <td>0.683638</td>\n",
       "      <td>Approved</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Certainly the words are of...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>700</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>4.675000</td>\n",
       "      <td>0.728884</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I evidently misread the wr...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>178</td>\n",
       "      <td>11.666667</td>\n",
       "      <td>3.885714</td>\n",
       "      <td>0.021653</td>\n",
       "      <td>Questionable</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      reviewText  overall  Review_Length  Sentence_Length  \\\n",
       "0  This is one of the first (...      5.0           1542        15.000000   \n",
       "1  The Prophet is Kahlil Gibr...      5.0           2294        22.705882   \n",
       "2  Gibran Khalil Gibran was b...      5.0            712        19.428571   \n",
       "3  Certainly the words are of...      5.0            700        21.000000   \n",
       "4  I evidently misread the wr...      2.0            178        11.666667   \n",
       "\n",
       "   Word_Length  Helpful_Rating         Badge                CountVectorizer  \\\n",
       "0     4.258865        0.902674          Gold  [0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "1     4.883289        0.683638      Approved  [0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "2     4.103704        0.683638      Approved  [0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "3     4.675000        0.728884        Bronze  [0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "4     3.885714        0.021653  Questionable  [0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "\n",
       "                         Bigrams  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0...  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0...  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0...  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bv = CountVectorizer(ngram_range=(2,2))\n",
    "bv_matrix = bv.fit_transform(norm_corpus)\n",
    "df['Bigrams'] = list(bv_matrix.toarray())\n",
    "df.head()\n",
    "\n",
    "# like one-hot encoding\n",
    "# how do i unpack the column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tfidf as Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>Review_Length</th>\n",
       "      <th>Sentence_Length</th>\n",
       "      <th>Word_Length</th>\n",
       "      <th>Helpful_Rating</th>\n",
       "      <th>Badge</th>\n",
       "      <th>CountVectorizer</th>\n",
       "      <th>Bigrams</th>\n",
       "      <th>Tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is one of the first (...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1542</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>4.258865</td>\n",
       "      <td>0.902674</td>\n",
       "      <td>Gold</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Prophet is Kahlil Gibr...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2294</td>\n",
       "      <td>22.705882</td>\n",
       "      <td>4.883289</td>\n",
       "      <td>0.683638</td>\n",
       "      <td>Approved</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gibran Khalil Gibran was b...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>712</td>\n",
       "      <td>19.428571</td>\n",
       "      <td>4.103704</td>\n",
       "      <td>0.683638</td>\n",
       "      <td>Approved</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Certainly the words are of...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>700</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>4.675000</td>\n",
       "      <td>0.728884</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I evidently misread the wr...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>178</td>\n",
       "      <td>11.666667</td>\n",
       "      <td>3.885714</td>\n",
       "      <td>0.021653</td>\n",
       "      <td>Questionable</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      reviewText  overall  Review_Length  Sentence_Length  \\\n",
       "0  This is one of the first (...      5.0           1542        15.000000   \n",
       "1  The Prophet is Kahlil Gibr...      5.0           2294        22.705882   \n",
       "2  Gibran Khalil Gibran was b...      5.0            712        19.428571   \n",
       "3  Certainly the words are of...      5.0            700        21.000000   \n",
       "4  I evidently misread the wr...      2.0            178        11.666667   \n",
       "\n",
       "   Word_Length  Helpful_Rating         Badge                CountVectorizer  \\\n",
       "0     4.258865        0.902674          Gold  [0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "1     4.883289        0.683638      Approved  [0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "2     4.103704        0.683638      Approved  [0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "3     4.675000        0.728884        Bronze  [0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "4     3.885714        0.021653  Questionable  [0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "\n",
       "                         Bigrams                          Tfidf  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0...  [0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0...  [0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0...  [0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0...  [0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0...  [0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tv = TfidfVectorizer(min_df=0., max_df=1., use_idf=True)\n",
    "tv_matrix = tv.fit_transform(norm_corpus)\n",
    "df['Tfidf'] = list(tv_matrix.toarray())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>9990</th>\n",
       "      <th>9991</th>\n",
       "      <th>9992</th>\n",
       "      <th>9993</th>\n",
       "      <th>9994</th>\n",
       "      <th>9995</th>\n",
       "      <th>9996</th>\n",
       "      <th>9997</th>\n",
       "      <th>9998</th>\n",
       "      <th>9999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.018129</td>\n",
       "      <td>0.060353</td>\n",
       "      <td>0.074323</td>\n",
       "      <td>0.005135</td>\n",
       "      <td>0.042192</td>\n",
       "      <td>0.058264</td>\n",
       "      <td>0.038531</td>\n",
       "      <td>0.060685</td>\n",
       "      <td>0.087176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005516</td>\n",
       "      <td>0.001186</td>\n",
       "      <td>0.012512</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048010</td>\n",
       "      <td>0.009460</td>\n",
       "      <td>0.013739</td>\n",
       "      <td>0.028397</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.018129</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.168503</td>\n",
       "      <td>0.223903</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080640</td>\n",
       "      <td>0.106214</td>\n",
       "      <td>0.145386</td>\n",
       "      <td>0.203932</td>\n",
       "      <td>0.055886</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038364</td>\n",
       "      <td>0.015407</td>\n",
       "      <td>0.026528</td>\n",
       "      <td>0.008915</td>\n",
       "      <td>0.018027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004575</td>\n",
       "      <td>0.010109</td>\n",
       "      <td>0.005696</td>\n",
       "      <td>0.004439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.060353</td>\n",
       "      <td>0.168503</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.232206</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.188338</td>\n",
       "      <td>0.092290</td>\n",
       "      <td>0.242701</td>\n",
       "      <td>0.356180</td>\n",
       "      <td>0.056427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004992</td>\n",
       "      <td>0.001687</td>\n",
       "      <td>0.009863</td>\n",
       "      <td>0.014727</td>\n",
       "      <td>0.025849</td>\n",
       "      <td>0.004113</td>\n",
       "      <td>0.047926</td>\n",
       "      <td>0.023938</td>\n",
       "      <td>0.009686</td>\n",
       "      <td>0.013935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.074323</td>\n",
       "      <td>0.223903</td>\n",
       "      <td>0.232206</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014013</td>\n",
       "      <td>0.185193</td>\n",
       "      <td>0.022578</td>\n",
       "      <td>0.075877</td>\n",
       "      <td>0.246898</td>\n",
       "      <td>0.086821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008969</td>\n",
       "      <td>0.003081</td>\n",
       "      <td>0.031415</td>\n",
       "      <td>0.003179</td>\n",
       "      <td>0.041549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003284</td>\n",
       "      <td>0.014684</td>\n",
       "      <td>0.001474</td>\n",
       "      <td>0.003187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005135</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014013</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009748</td>\n",
       "      <td>0.018329</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004201</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014901</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020959</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044611</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024555</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.042192</td>\n",
       "      <td>0.080640</td>\n",
       "      <td>0.188338</td>\n",
       "      <td>0.185193</td>\n",
       "      <td>0.009748</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.061176</td>\n",
       "      <td>0.122937</td>\n",
       "      <td>0.150652</td>\n",
       "      <td>0.060704</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035669</td>\n",
       "      <td>0.007789</td>\n",
       "      <td>0.036894</td>\n",
       "      <td>0.002276</td>\n",
       "      <td>0.034130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039083</td>\n",
       "      <td>0.017329</td>\n",
       "      <td>0.011828</td>\n",
       "      <td>0.012754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.058264</td>\n",
       "      <td>0.106214</td>\n",
       "      <td>0.092290</td>\n",
       "      <td>0.022578</td>\n",
       "      <td>0.018329</td>\n",
       "      <td>0.061176</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.077905</td>\n",
       "      <td>0.087576</td>\n",
       "      <td>0.059944</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061412</td>\n",
       "      <td>0.024074</td>\n",
       "      <td>0.060848</td>\n",
       "      <td>0.029459</td>\n",
       "      <td>0.057276</td>\n",
       "      <td>0.016813</td>\n",
       "      <td>0.046541</td>\n",
       "      <td>0.038864</td>\n",
       "      <td>0.028673</td>\n",
       "      <td>0.029403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.038531</td>\n",
       "      <td>0.145386</td>\n",
       "      <td>0.242701</td>\n",
       "      <td>0.075877</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.122937</td>\n",
       "      <td>0.077905</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.155644</td>\n",
       "      <td>0.040694</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030567</td>\n",
       "      <td>0.061481</td>\n",
       "      <td>0.071539</td>\n",
       "      <td>0.006048</td>\n",
       "      <td>0.083562</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.035753</td>\n",
       "      <td>0.002803</td>\n",
       "      <td>0.020583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.060685</td>\n",
       "      <td>0.203932</td>\n",
       "      <td>0.356180</td>\n",
       "      <td>0.246898</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150652</td>\n",
       "      <td>0.087576</td>\n",
       "      <td>0.155644</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.049612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015663</td>\n",
       "      <td>0.008221</td>\n",
       "      <td>0.018429</td>\n",
       "      <td>0.008592</td>\n",
       "      <td>0.020065</td>\n",
       "      <td>0.006924</td>\n",
       "      <td>0.018880</td>\n",
       "      <td>0.021604</td>\n",
       "      <td>0.025504</td>\n",
       "      <td>0.028516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.087176</td>\n",
       "      <td>0.055886</td>\n",
       "      <td>0.056427</td>\n",
       "      <td>0.086821</td>\n",
       "      <td>0.004201</td>\n",
       "      <td>0.060704</td>\n",
       "      <td>0.059944</td>\n",
       "      <td>0.040694</td>\n",
       "      <td>0.049612</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027798</td>\n",
       "      <td>0.036620</td>\n",
       "      <td>0.046627</td>\n",
       "      <td>0.016600</td>\n",
       "      <td>0.059505</td>\n",
       "      <td>0.033666</td>\n",
       "      <td>0.025963</td>\n",
       "      <td>0.063278</td>\n",
       "      <td>0.007311</td>\n",
       "      <td>0.022481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.079719</td>\n",
       "      <td>0.236134</td>\n",
       "      <td>0.237314</td>\n",
       "      <td>0.251392</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132250</td>\n",
       "      <td>0.097131</td>\n",
       "      <td>0.156355</td>\n",
       "      <td>0.233251</td>\n",
       "      <td>0.047509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028806</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.039609</td>\n",
       "      <td>0.003439</td>\n",
       "      <td>0.048699</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015024</td>\n",
       "      <td>0.027882</td>\n",
       "      <td>0.001594</td>\n",
       "      <td>0.014253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.022462</td>\n",
       "      <td>0.006403</td>\n",
       "      <td>0.003254</td>\n",
       "      <td>0.004597</td>\n",
       "      <td>0.017042</td>\n",
       "      <td>0.007597</td>\n",
       "      <td>0.021617</td>\n",
       "      <td>0.014881</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008603</td>\n",
       "      <td>0.003838</td>\n",
       "      <td>0.042083</td>\n",
       "      <td>0.039863</td>\n",
       "      <td>0.046431</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008288</td>\n",
       "      <td>0.021276</td>\n",
       "      <td>0.003719</td>\n",
       "      <td>0.008042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.035629</td>\n",
       "      <td>0.205486</td>\n",
       "      <td>0.195126</td>\n",
       "      <td>0.287790</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.077020</td>\n",
       "      <td>0.132657</td>\n",
       "      <td>0.074002</td>\n",
       "      <td>0.238854</td>\n",
       "      <td>0.005173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012890</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>0.026176</td>\n",
       "      <td>0.007945</td>\n",
       "      <td>0.017569</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008208</td>\n",
       "      <td>0.012739</td>\n",
       "      <td>0.013567</td>\n",
       "      <td>0.007965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.017566</td>\n",
       "      <td>0.019230</td>\n",
       "      <td>0.034411</td>\n",
       "      <td>0.007090</td>\n",
       "      <td>0.012060</td>\n",
       "      <td>0.055269</td>\n",
       "      <td>0.076377</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.010618</td>\n",
       "      <td>0.017732</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028160</td>\n",
       "      <td>0.007020</td>\n",
       "      <td>0.038367</td>\n",
       "      <td>0.006198</td>\n",
       "      <td>0.030610</td>\n",
       "      <td>0.018409</td>\n",
       "      <td>0.043443</td>\n",
       "      <td>0.015281</td>\n",
       "      <td>0.002873</td>\n",
       "      <td>0.012388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.014442</td>\n",
       "      <td>0.013028</td>\n",
       "      <td>0.001786</td>\n",
       "      <td>0.007366</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022530</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047995</td>\n",
       "      <td>0.007187</td>\n",
       "      <td>0.008806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003091</td>\n",
       "      <td>0.002758</td>\n",
       "      <td>0.059062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024791</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009296</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.085976</td>\n",
       "      <td>0.076781</td>\n",
       "      <td>0.189786</td>\n",
       "      <td>0.148940</td>\n",
       "      <td>0.005518</td>\n",
       "      <td>0.126534</td>\n",
       "      <td>0.101333</td>\n",
       "      <td>0.113886</td>\n",
       "      <td>0.166555</td>\n",
       "      <td>0.039863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025655</td>\n",
       "      <td>0.022428</td>\n",
       "      <td>0.076550</td>\n",
       "      <td>0.011407</td>\n",
       "      <td>0.067583</td>\n",
       "      <td>0.005040</td>\n",
       "      <td>0.045995</td>\n",
       "      <td>0.047869</td>\n",
       "      <td>0.020083</td>\n",
       "      <td>0.016432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009930</td>\n",
       "      <td>0.032458</td>\n",
       "      <td>0.007129</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005103</td>\n",
       "      <td>0.068447</td>\n",
       "      <td>0.056719</td>\n",
       "      <td>0.014198</td>\n",
       "      <td>0.006135</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013344</td>\n",
       "      <td>0.005953</td>\n",
       "      <td>0.029859</td>\n",
       "      <td>0.012444</td>\n",
       "      <td>0.018188</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012855</td>\n",
       "      <td>0.006536</td>\n",
       "      <td>0.016088</td>\n",
       "      <td>0.012474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.051590</td>\n",
       "      <td>0.125754</td>\n",
       "      <td>0.075208</td>\n",
       "      <td>0.105150</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133982</td>\n",
       "      <td>0.040302</td>\n",
       "      <td>0.063827</td>\n",
       "      <td>0.055331</td>\n",
       "      <td>0.053746</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019462</td>\n",
       "      <td>0.004322</td>\n",
       "      <td>0.021184</td>\n",
       "      <td>0.015066</td>\n",
       "      <td>0.016569</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004607</td>\n",
       "      <td>0.007526</td>\n",
       "      <td>0.007615</td>\n",
       "      <td>0.007537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.033832</td>\n",
       "      <td>0.080975</td>\n",
       "      <td>0.080939</td>\n",
       "      <td>0.013786</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026799</td>\n",
       "      <td>0.074542</td>\n",
       "      <td>0.049007</td>\n",
       "      <td>0.051795</td>\n",
       "      <td>0.117027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033425</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023434</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006033</td>\n",
       "      <td>0.008757</td>\n",
       "      <td>0.012717</td>\n",
       "      <td>0.026431</td>\n",
       "      <td>0.008795</td>\n",
       "      <td>0.052733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.057389</td>\n",
       "      <td>0.069835</td>\n",
       "      <td>0.251095</td>\n",
       "      <td>0.213769</td>\n",
       "      <td>0.005869</td>\n",
       "      <td>0.077564</td>\n",
       "      <td>0.022575</td>\n",
       "      <td>0.112908</td>\n",
       "      <td>0.201026</td>\n",
       "      <td>0.020574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008375</td>\n",
       "      <td>0.000561</td>\n",
       "      <td>0.008289</td>\n",
       "      <td>0.001172</td>\n",
       "      <td>0.016886</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001210</td>\n",
       "      <td>0.014262</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>0.015014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.077126</td>\n",
       "      <td>0.216932</td>\n",
       "      <td>0.219292</td>\n",
       "      <td>0.202929</td>\n",
       "      <td>0.007063</td>\n",
       "      <td>0.116805</td>\n",
       "      <td>0.078358</td>\n",
       "      <td>0.099877</td>\n",
       "      <td>0.160677</td>\n",
       "      <td>0.104343</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028898</td>\n",
       "      <td>0.006795</td>\n",
       "      <td>0.046174</td>\n",
       "      <td>0.019255</td>\n",
       "      <td>0.074535</td>\n",
       "      <td>0.027980</td>\n",
       "      <td>0.069294</td>\n",
       "      <td>0.053414</td>\n",
       "      <td>0.026374</td>\n",
       "      <td>0.015373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.072118</td>\n",
       "      <td>0.127618</td>\n",
       "      <td>0.209813</td>\n",
       "      <td>0.176860</td>\n",
       "      <td>0.005913</td>\n",
       "      <td>0.074318</td>\n",
       "      <td>0.056595</td>\n",
       "      <td>0.117439</td>\n",
       "      <td>0.179130</td>\n",
       "      <td>0.026657</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011674</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0.026981</td>\n",
       "      <td>0.003542</td>\n",
       "      <td>0.023523</td>\n",
       "      <td>0.004620</td>\n",
       "      <td>0.018245</td>\n",
       "      <td>0.023905</td>\n",
       "      <td>0.015771</td>\n",
       "      <td>0.007429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.050610</td>\n",
       "      <td>0.018298</td>\n",
       "      <td>0.032512</td>\n",
       "      <td>0.014269</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017692</td>\n",
       "      <td>0.053918</td>\n",
       "      <td>0.026841</td>\n",
       "      <td>0.015543</td>\n",
       "      <td>0.038549</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013026</td>\n",
       "      <td>0.009281</td>\n",
       "      <td>0.063567</td>\n",
       "      <td>0.029471</td>\n",
       "      <td>0.020033</td>\n",
       "      <td>0.021013</td>\n",
       "      <td>0.044148</td>\n",
       "      <td>0.016155</td>\n",
       "      <td>0.013196</td>\n",
       "      <td>0.034648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.066982</td>\n",
       "      <td>0.099392</td>\n",
       "      <td>0.068678</td>\n",
       "      <td>0.042577</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060524</td>\n",
       "      <td>0.067849</td>\n",
       "      <td>0.066311</td>\n",
       "      <td>0.064201</td>\n",
       "      <td>0.101169</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010102</td>\n",
       "      <td>0.001825</td>\n",
       "      <td>0.032524</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>0.020053</td>\n",
       "      <td>0.019573</td>\n",
       "      <td>0.029718</td>\n",
       "      <td>0.034705</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>0.006820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.070140</td>\n",
       "      <td>0.283828</td>\n",
       "      <td>0.430974</td>\n",
       "      <td>0.158701</td>\n",
       "      <td>0.002724</td>\n",
       "      <td>0.167617</td>\n",
       "      <td>0.130534</td>\n",
       "      <td>0.231103</td>\n",
       "      <td>0.328256</td>\n",
       "      <td>0.114285</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023042</td>\n",
       "      <td>0.009284</td>\n",
       "      <td>0.048936</td>\n",
       "      <td>0.013110</td>\n",
       "      <td>0.038824</td>\n",
       "      <td>0.005906</td>\n",
       "      <td>0.025876</td>\n",
       "      <td>0.033321</td>\n",
       "      <td>0.021602</td>\n",
       "      <td>0.028624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.101240</td>\n",
       "      <td>0.255261</td>\n",
       "      <td>0.386718</td>\n",
       "      <td>0.153267</td>\n",
       "      <td>0.005456</td>\n",
       "      <td>0.179267</td>\n",
       "      <td>0.097672</td>\n",
       "      <td>0.198487</td>\n",
       "      <td>0.263192</td>\n",
       "      <td>0.053002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007611</td>\n",
       "      <td>0.020752</td>\n",
       "      <td>0.023038</td>\n",
       "      <td>0.009369</td>\n",
       "      <td>0.024304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002251</td>\n",
       "      <td>0.001536</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>0.008720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.019364</td>\n",
       "      <td>0.013234</td>\n",
       "      <td>0.009602</td>\n",
       "      <td>0.006396</td>\n",
       "      <td>0.015200</td>\n",
       "      <td>0.025927</td>\n",
       "      <td>0.042565</td>\n",
       "      <td>0.008915</td>\n",
       "      <td>0.015098</td>\n",
       "      <td>0.016552</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018699</td>\n",
       "      <td>0.001832</td>\n",
       "      <td>0.021541</td>\n",
       "      <td>0.007033</td>\n",
       "      <td>0.020394</td>\n",
       "      <td>0.008638</td>\n",
       "      <td>0.024634</td>\n",
       "      <td>0.012271</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.018860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.029044</td>\n",
       "      <td>0.025964</td>\n",
       "      <td>0.023311</td>\n",
       "      <td>0.011392</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029621</td>\n",
       "      <td>0.034675</td>\n",
       "      <td>0.025183</td>\n",
       "      <td>0.009282</td>\n",
       "      <td>0.039427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035750</td>\n",
       "      <td>0.014684</td>\n",
       "      <td>0.035582</td>\n",
       "      <td>0.001052</td>\n",
       "      <td>0.037005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>0.015162</td>\n",
       "      <td>0.015379</td>\n",
       "      <td>0.001054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.002434</td>\n",
       "      <td>0.021804</td>\n",
       "      <td>0.003146</td>\n",
       "      <td>0.002687</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003602</td>\n",
       "      <td>0.010005</td>\n",
       "      <td>0.029765</td>\n",
       "      <td>0.018217</td>\n",
       "      <td>0.024802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005029</td>\n",
       "      <td>0.002244</td>\n",
       "      <td>0.026819</td>\n",
       "      <td>0.015007</td>\n",
       "      <td>0.006855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015274</td>\n",
       "      <td>0.010067</td>\n",
       "      <td>0.002174</td>\n",
       "      <td>0.013437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013655</td>\n",
       "      <td>0.012705</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>0.052037</td>\n",
       "      <td>0.010067</td>\n",
       "      <td>0.014199</td>\n",
       "      <td>0.004407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004339</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019465</td>\n",
       "      <td>0.041793</td>\n",
       "      <td>0.081092</td>\n",
       "      <td>0.004043</td>\n",
       "      <td>0.037377</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004177</td>\n",
       "      <td>0.016710</td>\n",
       "      <td>0.001874</td>\n",
       "      <td>0.004053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9970</th>\n",
       "      <td>0.008210</td>\n",
       "      <td>0.025403</td>\n",
       "      <td>0.026633</td>\n",
       "      <td>0.019503</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043372</td>\n",
       "      <td>0.046775</td>\n",
       "      <td>0.037858</td>\n",
       "      <td>0.028308</td>\n",
       "      <td>0.020074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051750</td>\n",
       "      <td>0.035247</td>\n",
       "      <td>0.091909</td>\n",
       "      <td>0.032320</td>\n",
       "      <td>0.039853</td>\n",
       "      <td>0.012266</td>\n",
       "      <td>0.035240</td>\n",
       "      <td>0.049742</td>\n",
       "      <td>0.033959</td>\n",
       "      <td>0.046520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9971</th>\n",
       "      <td>0.016544</td>\n",
       "      <td>0.013346</td>\n",
       "      <td>0.022468</td>\n",
       "      <td>0.009972</td>\n",
       "      <td>0.017005</td>\n",
       "      <td>0.032864</td>\n",
       "      <td>0.027253</td>\n",
       "      <td>0.036076</td>\n",
       "      <td>0.011611</td>\n",
       "      <td>0.039538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051344</td>\n",
       "      <td>0.026768</td>\n",
       "      <td>0.049494</td>\n",
       "      <td>0.012548</td>\n",
       "      <td>0.046793</td>\n",
       "      <td>0.017514</td>\n",
       "      <td>0.040502</td>\n",
       "      <td>0.036658</td>\n",
       "      <td>0.021350</td>\n",
       "      <td>0.032008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9972</th>\n",
       "      <td>0.039807</td>\n",
       "      <td>0.001245</td>\n",
       "      <td>0.009601</td>\n",
       "      <td>0.011872</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003840</td>\n",
       "      <td>0.016044</td>\n",
       "      <td>0.014235</td>\n",
       "      <td>0.002986</td>\n",
       "      <td>0.011721</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003422</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025690</td>\n",
       "      <td>0.023609</td>\n",
       "      <td>0.021664</td>\n",
       "      <td>0.016043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9973</th>\n",
       "      <td>0.013874</td>\n",
       "      <td>0.008046</td>\n",
       "      <td>0.006980</td>\n",
       "      <td>0.002462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010936</td>\n",
       "      <td>0.005296</td>\n",
       "      <td>0.009362</td>\n",
       "      <td>0.008345</td>\n",
       "      <td>0.015109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011990</td>\n",
       "      <td>0.013285</td>\n",
       "      <td>0.049465</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043630</td>\n",
       "      <td>0.017098</td>\n",
       "      <td>0.013246</td>\n",
       "      <td>0.010573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9974</th>\n",
       "      <td>0.023236</td>\n",
       "      <td>0.012114</td>\n",
       "      <td>0.001999</td>\n",
       "      <td>0.009282</td>\n",
       "      <td>0.018355</td>\n",
       "      <td>0.011652</td>\n",
       "      <td>0.012332</td>\n",
       "      <td>0.022949</td>\n",
       "      <td>0.002889</td>\n",
       "      <td>0.012644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028037</td>\n",
       "      <td>0.003086</td>\n",
       "      <td>0.041987</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010181</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012077</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9975</th>\n",
       "      <td>0.021957</td>\n",
       "      <td>0.016493</td>\n",
       "      <td>0.005938</td>\n",
       "      <td>0.018770</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031584</td>\n",
       "      <td>0.058603</td>\n",
       "      <td>0.030504</td>\n",
       "      <td>0.014830</td>\n",
       "      <td>0.028529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038849</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.048896</td>\n",
       "      <td>0.018122</td>\n",
       "      <td>0.030386</td>\n",
       "      <td>0.007301</td>\n",
       "      <td>0.047413</td>\n",
       "      <td>0.035514</td>\n",
       "      <td>0.016801</td>\n",
       "      <td>0.016782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9976</th>\n",
       "      <td>0.020607</td>\n",
       "      <td>0.021948</td>\n",
       "      <td>0.007184</td>\n",
       "      <td>0.009690</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.015655</td>\n",
       "      <td>0.027612</td>\n",
       "      <td>0.017307</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.022893</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042436</td>\n",
       "      <td>0.016446</td>\n",
       "      <td>0.042819</td>\n",
       "      <td>0.007059</td>\n",
       "      <td>0.032336</td>\n",
       "      <td>0.003946</td>\n",
       "      <td>0.018053</td>\n",
       "      <td>0.027464</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.011862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9977</th>\n",
       "      <td>0.015883</td>\n",
       "      <td>0.015809</td>\n",
       "      <td>0.001020</td>\n",
       "      <td>0.003702</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009819</td>\n",
       "      <td>0.038196</td>\n",
       "      <td>0.034495</td>\n",
       "      <td>0.002949</td>\n",
       "      <td>0.003022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006928</td>\n",
       "      <td>0.003878</td>\n",
       "      <td>0.045822</td>\n",
       "      <td>0.004815</td>\n",
       "      <td>0.015036</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017661</td>\n",
       "      <td>0.019939</td>\n",
       "      <td>0.002232</td>\n",
       "      <td>0.019757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9978</th>\n",
       "      <td>0.034342</td>\n",
       "      <td>0.012416</td>\n",
       "      <td>0.026074</td>\n",
       "      <td>0.015137</td>\n",
       "      <td>0.010792</td>\n",
       "      <td>0.020811</td>\n",
       "      <td>0.064298</td>\n",
       "      <td>0.028298</td>\n",
       "      <td>0.027141</td>\n",
       "      <td>0.030470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068411</td>\n",
       "      <td>0.053143</td>\n",
       "      <td>0.075232</td>\n",
       "      <td>0.046665</td>\n",
       "      <td>0.039112</td>\n",
       "      <td>0.024772</td>\n",
       "      <td>0.066428</td>\n",
       "      <td>0.085803</td>\n",
       "      <td>0.041421</td>\n",
       "      <td>0.038991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9979</th>\n",
       "      <td>0.017013</td>\n",
       "      <td>0.012173</td>\n",
       "      <td>0.003931</td>\n",
       "      <td>0.027839</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031106</td>\n",
       "      <td>0.012865</td>\n",
       "      <td>0.031066</td>\n",
       "      <td>0.006245</td>\n",
       "      <td>0.056920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026865</td>\n",
       "      <td>0.056053</td>\n",
       "      <td>0.087422</td>\n",
       "      <td>0.031683</td>\n",
       "      <td>0.089452</td>\n",
       "      <td>0.027988</td>\n",
       "      <td>0.003672</td>\n",
       "      <td>0.084134</td>\n",
       "      <td>0.056604</td>\n",
       "      <td>0.037771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9980</th>\n",
       "      <td>0.001234</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002193</td>\n",
       "      <td>0.009379</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003626</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011928</td>\n",
       "      <td>0.003562</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9981</th>\n",
       "      <td>0.026431</td>\n",
       "      <td>0.016517</td>\n",
       "      <td>0.016815</td>\n",
       "      <td>0.016969</td>\n",
       "      <td>0.009955</td>\n",
       "      <td>0.036422</td>\n",
       "      <td>0.044350</td>\n",
       "      <td>0.033990</td>\n",
       "      <td>0.023372</td>\n",
       "      <td>0.014016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038920</td>\n",
       "      <td>0.005794</td>\n",
       "      <td>0.061687</td>\n",
       "      <td>0.005116</td>\n",
       "      <td>0.029918</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005285</td>\n",
       "      <td>0.094408</td>\n",
       "      <td>0.020511</td>\n",
       "      <td>0.012719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982</th>\n",
       "      <td>0.006279</td>\n",
       "      <td>0.015297</td>\n",
       "      <td>0.001917</td>\n",
       "      <td>0.011925</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031239</td>\n",
       "      <td>0.101023</td>\n",
       "      <td>0.071041</td>\n",
       "      <td>0.051084</td>\n",
       "      <td>0.033301</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016251</td>\n",
       "      <td>0.008729</td>\n",
       "      <td>0.043068</td>\n",
       "      <td>0.012061</td>\n",
       "      <td>0.060715</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012460</td>\n",
       "      <td>0.044588</td>\n",
       "      <td>0.036702</td>\n",
       "      <td>0.038977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9983</th>\n",
       "      <td>0.011497</td>\n",
       "      <td>0.009166</td>\n",
       "      <td>0.001468</td>\n",
       "      <td>0.037452</td>\n",
       "      <td>0.028058</td>\n",
       "      <td>0.026170</td>\n",
       "      <td>0.016072</td>\n",
       "      <td>0.027087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004967</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009974</td>\n",
       "      <td>0.027456</td>\n",
       "      <td>0.042885</td>\n",
       "      <td>0.006931</td>\n",
       "      <td>0.017562</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021405</td>\n",
       "      <td>0.025962</td>\n",
       "      <td>0.003213</td>\n",
       "      <td>0.006948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9984</th>\n",
       "      <td>0.008062</td>\n",
       "      <td>0.007069</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.047297</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044869</td>\n",
       "      <td>0.024223</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.007774</td>\n",
       "      <td>0.011083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013171</td>\n",
       "      <td>0.002730</td>\n",
       "      <td>0.047310</td>\n",
       "      <td>0.002817</td>\n",
       "      <td>0.026215</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002910</td>\n",
       "      <td>0.017093</td>\n",
       "      <td>0.007157</td>\n",
       "      <td>0.020203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>0.006459</td>\n",
       "      <td>0.006514</td>\n",
       "      <td>0.006892</td>\n",
       "      <td>0.006180</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012198</td>\n",
       "      <td>0.040950</td>\n",
       "      <td>0.007568</td>\n",
       "      <td>0.010447</td>\n",
       "      <td>0.007808</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017935</td>\n",
       "      <td>0.006081</td>\n",
       "      <td>0.022773</td>\n",
       "      <td>0.010615</td>\n",
       "      <td>0.013112</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013623</td>\n",
       "      <td>0.025558</td>\n",
       "      <td>0.017317</td>\n",
       "      <td>0.016716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>0.016774</td>\n",
       "      <td>0.027862</td>\n",
       "      <td>0.004604</td>\n",
       "      <td>0.030446</td>\n",
       "      <td>0.004819</td>\n",
       "      <td>0.055530</td>\n",
       "      <td>0.048045</td>\n",
       "      <td>0.029477</td>\n",
       "      <td>0.020229</td>\n",
       "      <td>0.022861</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035388</td>\n",
       "      <td>0.006796</td>\n",
       "      <td>0.035784</td>\n",
       "      <td>0.007559</td>\n",
       "      <td>0.033077</td>\n",
       "      <td>0.003765</td>\n",
       "      <td>0.008450</td>\n",
       "      <td>0.042760</td>\n",
       "      <td>0.008064</td>\n",
       "      <td>0.013291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>0.013239</td>\n",
       "      <td>0.009945</td>\n",
       "      <td>0.032265</td>\n",
       "      <td>0.037403</td>\n",
       "      <td>0.006651</td>\n",
       "      <td>0.067610</td>\n",
       "      <td>0.042593</td>\n",
       "      <td>0.023473</td>\n",
       "      <td>0.009446</td>\n",
       "      <td>0.019807</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036003</td>\n",
       "      <td>0.028005</td>\n",
       "      <td>0.091021</td>\n",
       "      <td>0.015554</td>\n",
       "      <td>0.017435</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011603</td>\n",
       "      <td>0.047749</td>\n",
       "      <td>0.036521</td>\n",
       "      <td>0.020704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>0.005692</td>\n",
       "      <td>0.019907</td>\n",
       "      <td>0.002974</td>\n",
       "      <td>0.009807</td>\n",
       "      <td>0.053992</td>\n",
       "      <td>0.005850</td>\n",
       "      <td>0.027784</td>\n",
       "      <td>0.027015</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005002</td>\n",
       "      <td>0.002231</td>\n",
       "      <td>0.075953</td>\n",
       "      <td>0.004664</td>\n",
       "      <td>0.038277</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004818</td>\n",
       "      <td>0.039366</td>\n",
       "      <td>0.030257</td>\n",
       "      <td>0.007883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>0.022360</td>\n",
       "      <td>0.029392</td>\n",
       "      <td>0.007533</td>\n",
       "      <td>0.028045</td>\n",
       "      <td>0.010188</td>\n",
       "      <td>0.012555</td>\n",
       "      <td>0.047100</td>\n",
       "      <td>0.052266</td>\n",
       "      <td>0.003061</td>\n",
       "      <td>0.024501</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033804</td>\n",
       "      <td>0.022256</td>\n",
       "      <td>0.093134</td>\n",
       "      <td>0.020834</td>\n",
       "      <td>0.047854</td>\n",
       "      <td>0.011005</td>\n",
       "      <td>0.023194</td>\n",
       "      <td>0.030126</td>\n",
       "      <td>0.013208</td>\n",
       "      <td>0.017964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>0.005516</td>\n",
       "      <td>0.038364</td>\n",
       "      <td>0.004992</td>\n",
       "      <td>0.008969</td>\n",
       "      <td>0.014901</td>\n",
       "      <td>0.035669</td>\n",
       "      <td>0.061412</td>\n",
       "      <td>0.030567</td>\n",
       "      <td>0.015663</td>\n",
       "      <td>0.027798</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.164536</td>\n",
       "      <td>0.237357</td>\n",
       "      <td>0.139688</td>\n",
       "      <td>0.119410</td>\n",
       "      <td>0.053970</td>\n",
       "      <td>0.054110</td>\n",
       "      <td>0.199478</td>\n",
       "      <td>0.037675</td>\n",
       "      <td>0.138892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>0.001186</td>\n",
       "      <td>0.015407</td>\n",
       "      <td>0.001687</td>\n",
       "      <td>0.003081</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007789</td>\n",
       "      <td>0.024074</td>\n",
       "      <td>0.061481</td>\n",
       "      <td>0.008221</td>\n",
       "      <td>0.036620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164536</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.239271</td>\n",
       "      <td>0.112834</td>\n",
       "      <td>0.150652</td>\n",
       "      <td>0.083601</td>\n",
       "      <td>0.002742</td>\n",
       "      <td>0.230139</td>\n",
       "      <td>0.013182</td>\n",
       "      <td>0.102695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>0.012512</td>\n",
       "      <td>0.026528</td>\n",
       "      <td>0.009863</td>\n",
       "      <td>0.031415</td>\n",
       "      <td>0.020959</td>\n",
       "      <td>0.036894</td>\n",
       "      <td>0.060848</td>\n",
       "      <td>0.071539</td>\n",
       "      <td>0.018429</td>\n",
       "      <td>0.046627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.237357</td>\n",
       "      <td>0.239271</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.150640</td>\n",
       "      <td>0.247174</td>\n",
       "      <td>0.098199</td>\n",
       "      <td>0.069919</td>\n",
       "      <td>0.316756</td>\n",
       "      <td>0.057391</td>\n",
       "      <td>0.219037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008915</td>\n",
       "      <td>0.014727</td>\n",
       "      <td>0.003179</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002276</td>\n",
       "      <td>0.029459</td>\n",
       "      <td>0.006048</td>\n",
       "      <td>0.008592</td>\n",
       "      <td>0.016600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139688</td>\n",
       "      <td>0.112834</td>\n",
       "      <td>0.150640</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.075442</td>\n",
       "      <td>0.043689</td>\n",
       "      <td>0.005732</td>\n",
       "      <td>0.193442</td>\n",
       "      <td>0.015063</td>\n",
       "      <td>0.117460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>0.048010</td>\n",
       "      <td>0.018027</td>\n",
       "      <td>0.025849</td>\n",
       "      <td>0.041549</td>\n",
       "      <td>0.044611</td>\n",
       "      <td>0.034130</td>\n",
       "      <td>0.057276</td>\n",
       "      <td>0.083562</td>\n",
       "      <td>0.020065</td>\n",
       "      <td>0.059505</td>\n",
       "      <td>...</td>\n",
       "      <td>0.119410</td>\n",
       "      <td>0.150652</td>\n",
       "      <td>0.247174</td>\n",
       "      <td>0.075442</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.124323</td>\n",
       "      <td>0.033993</td>\n",
       "      <td>0.256212</td>\n",
       "      <td>0.025958</td>\n",
       "      <td>0.123907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.009460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004113</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016813</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006924</td>\n",
       "      <td>0.033666</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053970</td>\n",
       "      <td>0.083601</td>\n",
       "      <td>0.098199</td>\n",
       "      <td>0.043689</td>\n",
       "      <td>0.124323</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.087225</td>\n",
       "      <td>0.138008</td>\n",
       "      <td>0.006154</td>\n",
       "      <td>0.097920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.013739</td>\n",
       "      <td>0.004575</td>\n",
       "      <td>0.047926</td>\n",
       "      <td>0.003284</td>\n",
       "      <td>0.024555</td>\n",
       "      <td>0.039083</td>\n",
       "      <td>0.046541</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.018880</td>\n",
       "      <td>0.025963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054110</td>\n",
       "      <td>0.002742</td>\n",
       "      <td>0.069919</td>\n",
       "      <td>0.005732</td>\n",
       "      <td>0.033993</td>\n",
       "      <td>0.087225</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052832</td>\n",
       "      <td>0.044122</td>\n",
       "      <td>0.040250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.028397</td>\n",
       "      <td>0.010109</td>\n",
       "      <td>0.023938</td>\n",
       "      <td>0.014684</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017329</td>\n",
       "      <td>0.038864</td>\n",
       "      <td>0.035753</td>\n",
       "      <td>0.021604</td>\n",
       "      <td>0.063278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199478</td>\n",
       "      <td>0.230139</td>\n",
       "      <td>0.316756</td>\n",
       "      <td>0.193442</td>\n",
       "      <td>0.256212</td>\n",
       "      <td>0.138008</td>\n",
       "      <td>0.052832</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.060378</td>\n",
       "      <td>0.196836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005696</td>\n",
       "      <td>0.009686</td>\n",
       "      <td>0.001474</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011828</td>\n",
       "      <td>0.028673</td>\n",
       "      <td>0.002803</td>\n",
       "      <td>0.025504</td>\n",
       "      <td>0.007311</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037675</td>\n",
       "      <td>0.013182</td>\n",
       "      <td>0.057391</td>\n",
       "      <td>0.015063</td>\n",
       "      <td>0.025958</td>\n",
       "      <td>0.006154</td>\n",
       "      <td>0.044122</td>\n",
       "      <td>0.060378</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.016708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.004089</td>\n",
       "      <td>0.004439</td>\n",
       "      <td>0.013935</td>\n",
       "      <td>0.003187</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012754</td>\n",
       "      <td>0.029403</td>\n",
       "      <td>0.020583</td>\n",
       "      <td>0.028516</td>\n",
       "      <td>0.022481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138892</td>\n",
       "      <td>0.102695</td>\n",
       "      <td>0.219037</td>\n",
       "      <td>0.117460</td>\n",
       "      <td>0.123907</td>\n",
       "      <td>0.097920</td>\n",
       "      <td>0.040250</td>\n",
       "      <td>0.196836</td>\n",
       "      <td>0.016708</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 10000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6     \\\n",
       "0     1.000000  0.018129  0.060353  0.074323  0.005135  0.042192  0.058264   \n",
       "1     0.018129  1.000000  0.168503  0.223903  0.000000  0.080640  0.106214   \n",
       "2     0.060353  0.168503  1.000000  0.232206  0.000000  0.188338  0.092290   \n",
       "3     0.074323  0.223903  0.232206  1.000000  0.014013  0.185193  0.022578   \n",
       "4     0.005135  0.000000  0.000000  0.014013  1.000000  0.009748  0.018329   \n",
       "5     0.042192  0.080640  0.188338  0.185193  0.009748  1.000000  0.061176   \n",
       "6     0.058264  0.106214  0.092290  0.022578  0.018329  0.061176  1.000000   \n",
       "7     0.038531  0.145386  0.242701  0.075877  0.000000  0.122937  0.077905   \n",
       "8     0.060685  0.203932  0.356180  0.246898  0.000000  0.150652  0.087576   \n",
       "9     0.087176  0.055886  0.056427  0.086821  0.004201  0.060704  0.059944   \n",
       "10    0.079719  0.236134  0.237314  0.251392  0.000000  0.132250  0.097131   \n",
       "11    0.022462  0.006403  0.003254  0.004597  0.017042  0.007597  0.021617   \n",
       "12    0.035629  0.205486  0.195126  0.287790  0.000000  0.077020  0.132657   \n",
       "13    0.017566  0.019230  0.034411  0.007090  0.012060  0.055269  0.076377   \n",
       "14    0.014442  0.013028  0.001786  0.007366  0.000000  0.022530  0.000000   \n",
       "15    0.085976  0.076781  0.189786  0.148940  0.005518  0.126534  0.101333   \n",
       "16    0.000000  0.009930  0.032458  0.007129  0.000000  0.005103  0.068447   \n",
       "17    0.051590  0.125754  0.075208  0.105150  0.000000  0.133982  0.040302   \n",
       "18    0.033832  0.080975  0.080939  0.013786  0.000000  0.026799  0.074542   \n",
       "19    0.057389  0.069835  0.251095  0.213769  0.005869  0.077564  0.022575   \n",
       "20    0.077126  0.216932  0.219292  0.202929  0.007063  0.116805  0.078358   \n",
       "21    0.072118  0.127618  0.209813  0.176860  0.005913  0.074318  0.056595   \n",
       "22    0.050610  0.018298  0.032512  0.014269  0.000000  0.017692  0.053918   \n",
       "23    0.066982  0.099392  0.068678  0.042577  0.000000  0.060524  0.067849   \n",
       "24    0.070140  0.283828  0.430974  0.158701  0.002724  0.167617  0.130534   \n",
       "25    0.101240  0.255261  0.386718  0.153267  0.005456  0.179267  0.097672   \n",
       "26    0.019364  0.013234  0.009602  0.006396  0.015200  0.025927  0.042565   \n",
       "27    0.029044  0.025964  0.023311  0.011392  0.000000  0.029621  0.034675   \n",
       "28    0.002434  0.021804  0.003146  0.002687  0.000000  0.003602  0.010005   \n",
       "29    0.000000  0.013655  0.012705  0.002317  0.052037  0.010067  0.014199   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "9970  0.008210  0.025403  0.026633  0.019503  0.000000  0.043372  0.046775   \n",
       "9971  0.016544  0.013346  0.022468  0.009972  0.017005  0.032864  0.027253   \n",
       "9972  0.039807  0.001245  0.009601  0.011872  0.000000  0.003840  0.016044   \n",
       "9973  0.013874  0.008046  0.006980  0.002462  0.000000  0.010936  0.005296   \n",
       "9974  0.023236  0.012114  0.001999  0.009282  0.018355  0.011652  0.012332   \n",
       "9975  0.021957  0.016493  0.005938  0.018770  0.000000  0.031584  0.058603   \n",
       "9976  0.020607  0.021948  0.007184  0.009690  0.010101  0.015655  0.027612   \n",
       "9977  0.015883  0.015809  0.001020  0.003702  0.000000  0.009819  0.038196   \n",
       "9978  0.034342  0.012416  0.026074  0.015137  0.010792  0.020811  0.064298   \n",
       "9979  0.017013  0.012173  0.003931  0.027839  0.000000  0.031106  0.012865   \n",
       "9980  0.001234  0.001130  0.000000  0.000811  0.000000  0.000000  0.002193   \n",
       "9981  0.026431  0.016517  0.016815  0.016969  0.009955  0.036422  0.044350   \n",
       "9982  0.006279  0.015297  0.001917  0.011925  0.000000  0.031239  0.101023   \n",
       "9983  0.011497  0.009166  0.001468  0.037452  0.028058  0.026170  0.016072   \n",
       "9984  0.008062  0.007069  0.000895  0.047297  0.000000  0.044869  0.024223   \n",
       "9985  0.006459  0.006514  0.006892  0.006180  0.000000  0.012198  0.040950   \n",
       "9986  0.016774  0.027862  0.004604  0.030446  0.004819  0.055530  0.048045   \n",
       "9987  0.013239  0.009945  0.032265  0.037403  0.006651  0.067610  0.042593   \n",
       "9988  0.005692  0.019907  0.002974  0.009807  0.053992  0.005850  0.027784   \n",
       "9989  0.022360  0.029392  0.007533  0.028045  0.010188  0.012555  0.047100   \n",
       "9990  0.005516  0.038364  0.004992  0.008969  0.014901  0.035669  0.061412   \n",
       "9991  0.001186  0.015407  0.001687  0.003081  0.000000  0.007789  0.024074   \n",
       "9992  0.012512  0.026528  0.009863  0.031415  0.020959  0.036894  0.060848   \n",
       "9993  0.000000  0.008915  0.014727  0.003179  0.000000  0.002276  0.029459   \n",
       "9994  0.048010  0.018027  0.025849  0.041549  0.044611  0.034130  0.057276   \n",
       "9995  0.009460  0.000000  0.004113  0.000000  0.000000  0.000000  0.016813   \n",
       "9996  0.013739  0.004575  0.047926  0.003284  0.024555  0.039083  0.046541   \n",
       "9997  0.028397  0.010109  0.023938  0.014684  0.000000  0.017329  0.038864   \n",
       "9998  0.000000  0.005696  0.009686  0.001474  0.000000  0.011828  0.028673   \n",
       "9999  0.004089  0.004439  0.013935  0.003187  0.000000  0.012754  0.029403   \n",
       "\n",
       "          7         8         9       ...         9990      9991      9992  \\\n",
       "0     0.038531  0.060685  0.087176    ...     0.005516  0.001186  0.012512   \n",
       "1     0.145386  0.203932  0.055886    ...     0.038364  0.015407  0.026528   \n",
       "2     0.242701  0.356180  0.056427    ...     0.004992  0.001687  0.009863   \n",
       "3     0.075877  0.246898  0.086821    ...     0.008969  0.003081  0.031415   \n",
       "4     0.000000  0.000000  0.004201    ...     0.014901  0.000000  0.020959   \n",
       "5     0.122937  0.150652  0.060704    ...     0.035669  0.007789  0.036894   \n",
       "6     0.077905  0.087576  0.059944    ...     0.061412  0.024074  0.060848   \n",
       "7     1.000000  0.155644  0.040694    ...     0.030567  0.061481  0.071539   \n",
       "8     0.155644  1.000000  0.049612    ...     0.015663  0.008221  0.018429   \n",
       "9     0.040694  0.049612  1.000000    ...     0.027798  0.036620  0.046627   \n",
       "10    0.156355  0.233251  0.047509    ...     0.028806  0.003333  0.039609   \n",
       "11    0.014881  0.000000  0.003274    ...     0.008603  0.003838  0.042083   \n",
       "12    0.074002  0.238854  0.005173    ...     0.012890  0.007700  0.026176   \n",
       "13    0.039000  0.010618  0.017732    ...     0.028160  0.007020  0.038367   \n",
       "14    0.047995  0.007187  0.008806    ...     0.003091  0.002758  0.059062   \n",
       "15    0.113886  0.166555  0.039863    ...     0.025655  0.022428  0.076550   \n",
       "16    0.056719  0.014198  0.006135    ...     0.013344  0.005953  0.029859   \n",
       "17    0.063827  0.055331  0.053746    ...     0.019462  0.004322  0.021184   \n",
       "18    0.049007  0.051795  0.117027    ...     0.033425  0.000000  0.023434   \n",
       "19    0.112908  0.201026  0.020574    ...     0.008375  0.000561  0.008289   \n",
       "20    0.099877  0.160677  0.104343    ...     0.028898  0.006795  0.046174   \n",
       "21    0.117439  0.179130  0.026657    ...     0.011674  0.004136  0.026981   \n",
       "22    0.026841  0.015543  0.038549    ...     0.013026  0.009281  0.063567   \n",
       "23    0.066311  0.064201  0.101169    ...     0.010102  0.001825  0.032524   \n",
       "24    0.231103  0.328256  0.114285    ...     0.023042  0.009284  0.048936   \n",
       "25    0.198487  0.263192  0.053002    ...     0.007611  0.020752  0.023038   \n",
       "26    0.008915  0.015098  0.016552    ...     0.018699  0.001832  0.021541   \n",
       "27    0.025183  0.009282  0.039427    ...     0.035750  0.014684  0.035582   \n",
       "28    0.029765  0.018217  0.024802    ...     0.005029  0.002244  0.026819   \n",
       "29    0.004407  0.000000  0.004339    ...     0.019465  0.041793  0.081092   \n",
       "...        ...       ...       ...    ...          ...       ...       ...   \n",
       "9970  0.037858  0.028308  0.020074    ...     0.051750  0.035247  0.091909   \n",
       "9971  0.036076  0.011611  0.039538    ...     0.051344  0.026768  0.049494   \n",
       "9972  0.014235  0.002986  0.011721    ...     0.000000  0.000000  0.025448   \n",
       "9973  0.009362  0.008345  0.015109    ...     0.011990  0.013285  0.049465   \n",
       "9974  0.022949  0.002889  0.012644    ...     0.028037  0.003086  0.041987   \n",
       "9975  0.030504  0.014830  0.028529    ...     0.038849  0.022832  0.048896   \n",
       "9976  0.017307  0.009766  0.022893    ...     0.042436  0.016446  0.042819   \n",
       "9977  0.034495  0.002949  0.003022    ...     0.006928  0.003878  0.045822   \n",
       "9978  0.028298  0.027141  0.030470    ...     0.068411  0.053143  0.075232   \n",
       "9979  0.031066  0.006245  0.056920    ...     0.026865  0.056053  0.087422   \n",
       "9980  0.009379  0.000000  0.011321    ...     0.000000  0.000000  0.020156   \n",
       "9981  0.033990  0.023372  0.014016    ...     0.038920  0.005794  0.061687   \n",
       "9982  0.071041  0.051084  0.033301    ...     0.016251  0.008729  0.043068   \n",
       "9983  0.027087  0.000000  0.004967    ...     0.009974  0.027456  0.042885   \n",
       "9984  0.014900  0.007774  0.011083    ...     0.013171  0.002730  0.047310   \n",
       "9985  0.007568  0.010447  0.007808    ...     0.017935  0.006081  0.022773   \n",
       "9986  0.029477  0.020229  0.022861    ...     0.035388  0.006796  0.035784   \n",
       "9987  0.023473  0.009446  0.019807    ...     0.036003  0.028005  0.091021   \n",
       "9988  0.027015  0.000000  0.015056    ...     0.005002  0.002231  0.075953   \n",
       "9989  0.052266  0.003061  0.024501    ...     0.033804  0.022256  0.093134   \n",
       "9990  0.030567  0.015663  0.027798    ...     1.000000  0.164536  0.237357   \n",
       "9991  0.061481  0.008221  0.036620    ...     0.164536  1.000000  0.239271   \n",
       "9992  0.071539  0.018429  0.046627    ...     0.237357  0.239271  1.000000   \n",
       "9993  0.006048  0.008592  0.016600    ...     0.139688  0.112834  0.150640   \n",
       "9994  0.083562  0.020065  0.059505    ...     0.119410  0.150652  0.247174   \n",
       "9995  0.000000  0.006924  0.033666    ...     0.053970  0.083601  0.098199   \n",
       "9996  0.006248  0.018880  0.025963    ...     0.054110  0.002742  0.069919   \n",
       "9997  0.035753  0.021604  0.063278    ...     0.199478  0.230139  0.316756   \n",
       "9998  0.002803  0.025504  0.007311    ...     0.037675  0.013182  0.057391   \n",
       "9999  0.020583  0.028516  0.022481    ...     0.138892  0.102695  0.219037   \n",
       "\n",
       "          9993      9994      9995      9996      9997      9998      9999  \n",
       "0     0.000000  0.048010  0.009460  0.013739  0.028397  0.000000  0.004089  \n",
       "1     0.008915  0.018027  0.000000  0.004575  0.010109  0.005696  0.004439  \n",
       "2     0.014727  0.025849  0.004113  0.047926  0.023938  0.009686  0.013935  \n",
       "3     0.003179  0.041549  0.000000  0.003284  0.014684  0.001474  0.003187  \n",
       "4     0.000000  0.044611  0.000000  0.024555  0.000000  0.000000  0.000000  \n",
       "5     0.002276  0.034130  0.000000  0.039083  0.017329  0.011828  0.012754  \n",
       "6     0.029459  0.057276  0.016813  0.046541  0.038864  0.028673  0.029403  \n",
       "7     0.006048  0.083562  0.000000  0.006248  0.035753  0.002803  0.020583  \n",
       "8     0.008592  0.020065  0.006924  0.018880  0.021604  0.025504  0.028516  \n",
       "9     0.016600  0.059505  0.033666  0.025963  0.063278  0.007311  0.022481  \n",
       "10    0.003439  0.048699  0.000000  0.015024  0.027882  0.001594  0.014253  \n",
       "11    0.039863  0.046431  0.000000  0.008288  0.021276  0.003719  0.008042  \n",
       "12    0.007945  0.017569  0.000000  0.008208  0.012739  0.013567  0.007965  \n",
       "13    0.006198  0.030610  0.018409  0.043443  0.015281  0.002873  0.012388  \n",
       "14    0.000000  0.024791  0.000000  0.000000  0.009296  0.000000  0.000000  \n",
       "15    0.011407  0.067583  0.005040  0.045995  0.047869  0.020083  0.016432  \n",
       "16    0.012444  0.018188  0.000000  0.012855  0.006536  0.016088  0.012474  \n",
       "17    0.015066  0.016569  0.000000  0.004607  0.007526  0.007615  0.007537  \n",
       "18    0.000000  0.006033  0.008757  0.012717  0.026431  0.008795  0.052733  \n",
       "19    0.001172  0.016886  0.000000  0.001210  0.014262  0.000543  0.015014  \n",
       "20    0.019255  0.074535  0.027980  0.069294  0.053414  0.026374  0.015373  \n",
       "21    0.003542  0.023523  0.004620  0.018245  0.023905  0.015771  0.007429  \n",
       "22    0.029471  0.020033  0.021013  0.044148  0.016155  0.013196  0.034648  \n",
       "23    0.001250  0.020053  0.019573  0.029718  0.034705  0.000580  0.006820  \n",
       "24    0.013110  0.038824  0.005906  0.025876  0.033321  0.021602  0.028624  \n",
       "25    0.009369  0.024304  0.000000  0.002251  0.001536  0.001010  0.008720  \n",
       "26    0.007033  0.020394  0.008638  0.024634  0.012271  0.019380  0.018860  \n",
       "27    0.001052  0.037005  0.000000  0.001087  0.015162  0.015379  0.001054  \n",
       "28    0.015007  0.006855  0.000000  0.015274  0.010067  0.002174  0.013437  \n",
       "29    0.004043  0.037377  0.000000  0.004177  0.016710  0.001874  0.004053  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "9970  0.032320  0.039853  0.012266  0.035240  0.049742  0.033959  0.046520  \n",
       "9971  0.012548  0.046793  0.017514  0.040502  0.036658  0.021350  0.032008  \n",
       "9972  0.000000  0.003422  0.000000  0.025690  0.023609  0.021664  0.016043  \n",
       "9973  0.000000  0.009412  0.000000  0.043630  0.017098  0.013246  0.010573  \n",
       "9974  0.000000  0.010181  0.000000  0.000000  0.012077  0.000000  0.035453  \n",
       "9975  0.018122  0.030386  0.007301  0.047413  0.035514  0.016801  0.016782  \n",
       "9976  0.007059  0.032336  0.003946  0.018053  0.027464  0.007381  0.011862  \n",
       "9977  0.004815  0.015036  0.000000  0.017661  0.019939  0.002232  0.019757  \n",
       "9978  0.046665  0.039112  0.024772  0.066428  0.085803  0.041421  0.038991  \n",
       "9979  0.031683  0.089452  0.027988  0.003672  0.084134  0.056604  0.037771  \n",
       "9980  0.000000  0.003626  0.000000  0.011928  0.003562  0.000000  0.000000  \n",
       "9981  0.005116  0.029918  0.000000  0.005285  0.094408  0.020511  0.012719  \n",
       "9982  0.012061  0.060715  0.000000  0.012460  0.044588  0.036702  0.038977  \n",
       "9983  0.006931  0.017562  0.000000  0.021405  0.025962  0.003213  0.006948  \n",
       "9984  0.002817  0.026215  0.000000  0.002910  0.017093  0.007157  0.020203  \n",
       "9985  0.010615  0.013112  0.000000  0.013623  0.025558  0.017317  0.016716  \n",
       "9986  0.007559  0.033077  0.003765  0.008450  0.042760  0.008064  0.013291  \n",
       "9987  0.015554  0.017435  0.000000  0.011603  0.047749  0.036521  0.020704  \n",
       "9988  0.004664  0.038277  0.000000  0.004818  0.039366  0.030257  0.007883  \n",
       "9989  0.020834  0.047854  0.011005  0.023194  0.030126  0.013208  0.017964  \n",
       "9990  0.139688  0.119410  0.053970  0.054110  0.199478  0.037675  0.138892  \n",
       "9991  0.112834  0.150652  0.083601  0.002742  0.230139  0.013182  0.102695  \n",
       "9992  0.150640  0.247174  0.098199  0.069919  0.316756  0.057391  0.219037  \n",
       "9993  1.000000  0.075442  0.043689  0.005732  0.193442  0.015063  0.117460  \n",
       "9994  0.075442  1.000000  0.124323  0.033993  0.256212  0.025958  0.123907  \n",
       "9995  0.043689  0.124323  1.000000  0.087225  0.138008  0.006154  0.097920  \n",
       "9996  0.005732  0.033993  0.087225  1.000000  0.052832  0.044122  0.040250  \n",
       "9997  0.193442  0.256212  0.138008  0.052832  1.000000  0.060378  0.196836  \n",
       "9998  0.015063  0.025958  0.006154  0.044122  0.060378  1.000000  0.016708  \n",
       "9999  0.117460  0.123907  0.097920  0.040250  0.196836  0.016708  1.000000  \n",
       "\n",
       "[10000 rows x 10000 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarity_matrix = cosine_similarity(tv_matrix)\n",
    "similarity_df = pd.DataFrame(similarity_matrix)\n",
    "similarity_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Overall with Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7684\n",
      "0.4616\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(norm_corpus)\n",
    "X = X.tocsc()  # some versions of sklearn return COO format\n",
    "y = df.overall\n",
    "\n",
    "# Split into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# Create a multinomial classifier\n",
    "clf = MultinomialNB()\n",
    "\n",
    "# Fit the classifier to the data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Print the accuracy\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Overall with Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41213333333333335\n",
      "0.4168\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=0., max_df=1., use_idf=True)\n",
    "X = vectorizer.fit_transform(norm_corpus)\n",
    "X = X.tocsc()  # some versions of sklearn return COO format\n",
    "y = df.overall\n",
    "\n",
    "# Split into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# Create a multinomial classifier\n",
    "clf = MultinomialNB()\n",
    "\n",
    "# Fit the classifier to the data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Print the accuracy\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Overall with Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9989333333333333\n",
      "0.3224\n"
     ]
    }
   ],
   "source": [
    "bv = CountVectorizer(ngram_range=(2,2))\n",
    "X = bv.fit_transform(norm_corpus)\n",
    "X = X.tocsc()  # some versions of sklearn return COO format\n",
    "y = df.overall\n",
    "\n",
    "# Split into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# Create a multinomial classifier\n",
    "clf = MultinomialNB()\n",
    "\n",
    "# Fit the classifier to the data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Print the accuracy\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of y before reshaping: (10000,)\n",
      "Dimensions of X before reshaping: (10000,)\n",
      "Dimensions of y after reshaping: (10000, 1)\n",
      "Dimensions of X after reshaping: (10000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# Create arrays for features and target variable\n",
    "y = df['overall']\n",
    "X = df['CountVectorizer']\n",
    "\n",
    "# Print the dimensions of X and y before reshaping\n",
    "print(\"Dimensions of y before reshaping: {}\".format(y.shape))\n",
    "print(\"Dimensions of X before reshaping: {}\".format(X.shape))\n",
    "\n",
    "# Reshape X and y\n",
    "y = y.reshape(-1,1)\n",
    "X = X.reshape(-1,1)\n",
    "\n",
    "# Print the dimensions of X and y after reshaping\n",
    "print(\"Dimensions of y after reshaping: {}\".format(y.shape))\n",
    "print(\"Dimensions of X after reshaping: {}\".format(X.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.2395631049274204\n",
      "Root Mean Squared Error: 1.332624665735047\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)\n",
    "\n",
    "# Create the regressor: reg_all\n",
    "reg_all = LinearRegression()\n",
    "\n",
    "# Fit the regressor to the training data\n",
    "reg_all.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data: y_pred\n",
    "y_pred = reg_all.predict(X_test)\n",
    "\n",
    "# Compute and print R^2 and RMSE\n",
    "print(\"R^2: {}\".format(reg_all.score(X_test, y_test)))\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Root Mean Squared Error: {}\".format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.loc[0, 'CountVectorizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the necessary imports\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Create a TruncatedSVD instance: svd\n",
    "svd = TruncatedSVD(n_components=50)\n",
    "\n",
    "# Create a KMeans instance: kmeans\n",
    "kmeans = KMeans(n_clusters=6)\n",
    "\n",
    "# Create a pipeline: pipeline\n",
    "pipeline = make_pipeline(svd, kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check scikit learn linear regression example countvectorizer\n",
    "# check word2vec\n",
    "# boosted trees, random forests, \n",
    "# helpful, unhelpful\n",
    "\n",
    "# text blob (python package)- great sentiment analysis function\n",
    "# 5-star rating system- 1,2 bad / 3 questionable / 4,5 good\n",
    "# consider mean +- standard deviation, quartiles, etc.\n",
    "# distribution should determine it, harmonic mean\n",
    "\n",
    "# use probabilities after binary split to return 1-5, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# google countvectorizer other features, side features\n",
    "# google nlp feature engineering\n",
    "# word2vec\n",
    "# pos tagging (before stripping punctuation)\n",
    "# sentence tokenizer\n",
    "# nltk\n",
    "# gensim\n",
    "# pyLBAvis (visualization of LBA models)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
